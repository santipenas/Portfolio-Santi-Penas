{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b365aeb5-6e10-417a-bd4c-6b87a9569f3e",
   "metadata": {},
   "source": [
    "## Proyecto Off-Platform Project: Machine Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febae7e8-9046-4fb7-a7ef-59d7a1d49861",
   "metadata": {},
   "source": [
    "*PROJECT IN POGRESS AND STILL UNDER CONSTRUCTION*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "142728df-c632-4eb8-a06b-85135cea26f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b2a9cf5-209c-48c4-a03d-c6d95ad168a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e20b1a2b-d747-4e8e-b82e-35da13fb629a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters & File Paths\n",
    "\n",
    "DATA_PATH = \"ita.txt\"  # Change this path to your translation dataset file\n",
    "NUM_LINES = 500        # Number of lines to process (adjust as needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7408067-d56f-4f76-a736-5d6ea3c32d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "LATENT_DIM = 256       # Dimensionality of the LSTM hidden states\n",
    "BATCH_SIZE = 80\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730668a4-0fe3-4041-88c3-b7444d124bf2",
   "metadata": {},
   "source": [
    "### Data Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3faf9da-91f8-445b-908e-3e2e223385ed",
   "metadata": {},
   "outputs": [],
   "source": [
    " \"\"\" Loads and preprocesses the dataset.\n",
    "     Returns: \n",
    "      input_texts: List of source sentences.\n",
    "      target_texts: List of target sentences (with start/end tokens).\n",
    "      input_tokens: Sorted list of unique tokens in the source language.\n",
    "      target_tokens: Sorted list of unique tokens in the target language.  \"\"\"\n",
    "def load_data(data_path: str, num_lines: int):\n",
    "    if not Path(data_path).exists():\n",
    "        raise FileNotFoundError(f\"Data file {data_path} not found.\")\n",
    "\n",
    "    with open(data_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.read().split('\\n')\n",
    "\n",
    "    input_texts = []\n",
    "    target_texts = []\n",
    "    input_token_set = set()\n",
    "    target_token_set = set()\n",
    "\n",
    "    for line in lines[:num_lines]:\n",
    "        # Expecting each line to contain at least two tab-separated columns\n",
    "        parts = line.split('\\t')\n",
    "        if len(parts) < 2:\n",
    "            continue\n",
    "        input_text, target_text = parts[0], parts[1]\n",
    "        input_texts.append(input_text)\n",
    "        \n",
    "        # Use regex to split punctuation from words\n",
    "        target_text = \" \".join(re.findall(r\"[\\w']+|[^\\s\\w]\", target_text))\n",
    "        # Add start and end tokens to target sentence\n",
    "        target_text = '<START> ' + target_text + ' <END>'\n",
    "        target_texts.append(target_text)\n",
    "\n",
    "        # Build token sets from input (using regex tokenization) and target (space-split)\n",
    "        for token in re.findall(r\"[\\w']+|[^\\s\\w]\", input_text):\n",
    "            input_token_set.add(token)\n",
    "        for token in target_text.split():\n",
    "            target_token_set.add(token)\n",
    "\n",
    "    input_tokens = sorted(list(input_token_set))\n",
    "    target_tokens = sorted(list(target_token_set))\n",
    "    \n",
    "    return input_texts, target_texts, input_tokens, target_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f81081e-5dd8-4a26-9b9e-f7b05af76251",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Converts input and target texts into one-hot encoded 3D numpy arrays.  Returns: encoder_input_data, decoder_input_data, decoder_target_data, \n",
    "          input_features_dict, target_features_dict, reverse_target_features_dict, max_encoder_seq_length, max_decoder_seq_length. \"\"\"\n",
    "def vectorize_data(input_texts, target_texts, input_tokens, target_tokens):\n",
    "    num_encoder_tokens = len(input_tokens)\n",
    "    num_decoder_tokens = len(target_tokens)\n",
    "    max_encoder_seq_length = max(len(re.findall(r\"[\\w']+|[^\\s\\w]\", txt)) for txt in input_texts)\n",
    "    max_decoder_seq_length = max(len(txt.split()) for txt in target_texts)\n",
    "    \n",
    "    # Create token-index mappings\n",
    "    input_features_dict = {token: i for i, token in enumerate(input_tokens)}\n",
    "    target_features_dict = {token: i for i, token in enumerate(target_tokens)}\n",
    "    reverse_target_features_dict = {i: token for token, i in target_features_dict.items()}\n",
    "\n",
    "    encoder_input_data = np.zeros((len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n",
    "    decoder_input_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
    "    decoder_target_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
    "\n",
    "    for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "        # One-hot encode input sequence\n",
    "        for t, token in enumerate(re.findall(r\"[\\w']+|[^\\s\\w]\", input_text)):\n",
    "            encoder_input_data[i, t, input_features_dict[token]] = 1.\n",
    "        # One-hot encode decoder input and target sequences\n",
    "        target_tokens_seq = target_text.split()\n",
    "        for t, token in enumerate(target_tokens_seq):\n",
    "            decoder_input_data[i, t, target_features_dict[token]] = 1.\n",
    "            if t > 0:\n",
    "                # Decoder target data is ahead by one timestep\n",
    "                decoder_target_data[i, t - 1, target_features_dict[token]] = 1.\n",
    "    \n",
    "    return (encoder_input_data, decoder_input_data, decoder_target_data,\n",
    "            input_features_dict, target_features_dict, reverse_target_features_dict,\n",
    "            max_encoder_seq_length, max_decoder_seq_length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2205ee-5163-4214-a1d2-2ed716992d31",
   "metadata": {},
   "source": [
    "### Model Building Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0f65e68-79d1-44a6-866a-2e29a72ca724",
   "metadata": {},
   "outputs": [],
   "source": [
    " \"\"\" Builds the encoder-decoder training model. Returns: training_model, encoder_inputs, decoder_inputs, decoder_lstm, decoder_dense.\"\"\"\n",
    "def build_training_model(num_encoder_tokens, num_decoder_tokens, latent_dim):\n",
    "    # Define encoder\n",
    "    encoder_inputs = Input(shape=(None, num_encoder_tokens), name='encoder_inputs')\n",
    "    encoder_lstm = LSTM(latent_dim, return_state=True, name='encoder_lstm')\n",
    "    encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "    encoder_states = [state_h, state_c]\n",
    "    \n",
    "    # Define decoder\n",
    "    decoder_inputs = Input(shape=(None, num_decoder_tokens), name='decoder_inputs')\n",
    "    decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, name='decoder_lstm')\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "    decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='decoder_dense')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "    training_model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    return training_model, encoder_inputs, decoder_inputs, decoder_lstm, decoder_dense\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3190a0d9-9eec-4f44-a8a7-4e037e2f5bd2",
   "metadata": {},
   "source": [
    "### Inference Model Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd77eee6-0c87-45c6-8014-a581fca331b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Constructs the encoder and decoder models for inference. Returns: encoder_model, decoder_model.\"\"\"\n",
    "def build_inference_models(training_model, latent_dim, num_encoder_tokens, num_decoder_tokens):\n",
    "    # Encoder inference model\n",
    "    encoder_inputs = training_model.input[0]  # input placeholder for encoder\n",
    "    encoder_outputs, state_h_enc, state_c_enc = training_model.get_layer('encoder_lstm').output\n",
    "    encoder_states = [state_h_enc, state_c_enc]\n",
    "    encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "    # Decoder inference model\n",
    "    decoder_inputs = training_model.input[1]  # input placeholder for decoder\n",
    "    decoder_state_input_h = Input(shape=(latent_dim,), name='input_h')\n",
    "    decoder_state_input_c = Input(shape=(latent_dim,), name='input_c')\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    decoder_lstm = training_model.get_layer('decoder_lstm')\n",
    "    decoder_dense = training_model.get_layer('decoder_dense')\n",
    "    \n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h, state_c]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "    \n",
    "    return encoder_model, decoder_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74176fcf-8bf5-4724-ad0f-d46fbb43fc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Decodes an input sequence to generate the translated sentence.\"\"\"\n",
    "def decode_sequence(test_input, encoder_model, decoder_model, target_features_dict, reverse_target_features_dict, max_decoder_seq_length, num_decoder_tokens, latent_dim):\n",
    "    # Encode the input sequence\n",
    "    states_value = encoder_model.predict(test_input)\n",
    "\n",
    "    # Generate empty target sequence of length 1\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, target_features_dict['<START>']] = 1.\n",
    "\n",
    "    decoded_sentence = \"\"\n",
    "    stop_condition = False\n",
    "\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        # Get token with highest probability\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = reverse_target_features_dict[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "\n",
    "        # Exit if hit <END> or max length reached\n",
    "        if sampled_token == '<END>' or len(decoded_sentence.split()) > max_decoder_seq_length:\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (length 1)\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a271a8-d5a1-40fd-92d4-a21ff9de813e",
   "metadata": {},
   "source": [
    "### Main Execution: Training & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c12fcd97-a863-4aeb-81d0-8f6f3eb5eef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing data...\n",
      "Number of samples: 500\n",
      "Number of unique input tokens: 143\n",
      "Number of unique output tokens: 428\n",
      "Max sequence length for inputs: 4\n",
      "Max sequence length for outputs: 8\n",
      "\n",
      "Building the training model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">143</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ decoder_inputs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">428</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ encoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)           │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">409,600</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│                               │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]        │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ decoder_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)           │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">701,440</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)] │                 │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],        │\n",
       "│                               │                           │                 │ encoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ decoder_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">428</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">109,996</span> │ decoder_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ encoder_inputs (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m143\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ decoder_inputs (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m428\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ encoder_lstm (\u001b[38;5;33mLSTM\u001b[0m)           │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │         \u001b[38;5;34m409,600\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│                               │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]        │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ decoder_lstm (\u001b[38;5;33mLSTM\u001b[0m)           │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),       │         \u001b[38;5;34m701,440\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)] │                 │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],        │\n",
       "│                               │                           │                 │ encoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]         │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ decoder_dense (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m428\u001b[0m)         │         \u001b[38;5;34m109,996\u001b[0m │ decoder_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,221,036</span> (4.66 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,221,036\u001b[0m (4.66 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,221,036</span> (4.66 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,221,036\u001b[0m (4.66 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training the model...\n",
      "Epoch 1/50\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0444 - loss: 2.8208 \n",
      "Epoch 1: val_loss improved from inf to 2.93068, saving model to training_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 178ms/step - accuracy: 0.0595 - loss: 2.8258 - val_accuracy: 0.1275 - val_loss: 2.9307\n",
      "Epoch 2/50\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.1280 - loss: 2.7830\n",
      "Epoch 2: val_loss improved from 2.93068 to 2.87241, saving model to training_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.1275 - loss: 2.7871 - val_accuracy: 0.1250 - val_loss: 2.8724\n",
      "Epoch 3/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.1250 - loss: 2.7169\n",
      "Epoch 3: val_loss improved from 2.87241 to 2.67918, saving model to training_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.1250 - loss: 2.7154 - val_accuracy: 0.1250 - val_loss: 2.6792\n",
      "Epoch 4/50\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.1250 - loss: 2.4938\n",
      "Epoch 4: val_loss improved from 2.67918 to 2.31089, saving model to training_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.1250 - loss: 2.4689 - val_accuracy: 0.1250 - val_loss: 2.3109\n",
      "Epoch 5/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.1250 - loss: 2.1587\n",
      "Epoch 5: val_loss improved from 2.31089 to 2.04619, saving model to training_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.1250 - loss: 2.1516 - val_accuracy: 0.1250 - val_loss: 2.0462\n",
      "Epoch 6/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.1250 - loss: 1.8986\n",
      "Epoch 6: val_loss improved from 2.04619 to 1.88626, saving model to training_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.1250 - loss: 1.8949 - val_accuracy: 0.1250 - val_loss: 1.8863\n",
      "Epoch 7/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.1250 - loss: 1.7663\n",
      "Epoch 7: val_loss did not improve from 1.88626\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.1250 - loss: 1.7682 - val_accuracy: 0.1250 - val_loss: 1.9207\n",
      "Epoch 8/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.1250 - loss: 1.7563\n",
      "Epoch 8: val_loss improved from 1.88626 to 1.85748, saving model to training_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.1250 - loss: 1.7570 - val_accuracy: 0.1250 - val_loss: 1.8575\n",
      "Epoch 9/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.1270 - loss: 1.7215\n",
      "Epoch 9: val_loss did not improve from 1.85748\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.1279 - loss: 1.7241 - val_accuracy: 0.1700 - val_loss: 1.8604\n",
      "Epoch 10/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.1586 - loss: 1.7106\n",
      "Epoch 10: val_loss did not improve from 1.85748\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.1586 - loss: 1.7130 - val_accuracy: 0.1700 - val_loss: 1.8591\n",
      "Epoch 11/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.1586 - loss: 1.7007\n",
      "Epoch 11: val_loss did not improve from 1.85748\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.1586 - loss: 1.7030 - val_accuracy: 0.1700 - val_loss: 1.8611\n",
      "Epoch 12/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.1586 - loss: 1.6938\n",
      "Epoch 12: val_loss improved from 1.85748 to 1.84700, saving model to training_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.1586 - loss: 1.6963 - val_accuracy: 0.1700 - val_loss: 1.8470\n",
      "Epoch 13/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.1586 - loss: 1.6855\n",
      "Epoch 13: val_loss did not improve from 1.84700\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.1586 - loss: 1.6884 - val_accuracy: 0.1700 - val_loss: 1.8663\n",
      "Epoch 14/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.1586 - loss: 1.6838\n",
      "Epoch 14: val_loss did not improve from 1.84700\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.1586 - loss: 1.6861 - val_accuracy: 0.1700 - val_loss: 1.8510\n",
      "Epoch 15/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.1586 - loss: 1.6746\n",
      "Epoch 15: val_loss did not improve from 1.84700\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.1586 - loss: 1.6774 - val_accuracy: 0.1700 - val_loss: 1.8696\n",
      "Epoch 16/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.1586 - loss: 1.6763\n",
      "Epoch 16: val_loss did not improve from 1.84700\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.1586 - loss: 1.6786 - val_accuracy: 0.1700 - val_loss: 1.8561\n",
      "Epoch 17/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.1586 - loss: 1.6682\n",
      "Epoch 17: val_loss did not improve from 1.84700\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.1586 - loss: 1.6711 - val_accuracy: 0.1700 - val_loss: 1.8746\n",
      "Epoch 17: early stopping\n",
      "\n",
      "Loading the best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decoding test sequences...\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: . . <END>\n",
      "--------------------------------------------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: . . <END>\n",
      "--------------------------------------------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Input sentence: Run!\n",
      "Decoded sentence: . . <END>\n",
      "--------------------------------------------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Input sentence: Run!\n",
      "Decoded sentence: . . <END>\n",
      "--------------------------------------------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Input sentence: Run!\n",
      "Decoded sentence: . . <END>\n",
      "--------------------------------------------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Input sentence: Who?\n",
      "Decoded sentence: . . <END>\n",
      "--------------------------------------------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: . . <END>\n",
      "--------------------------------------------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Input sentence: Duck!\n",
      "Decoded sentence: . . <END>\n",
      "--------------------------------------------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Input sentence: Duck!\n",
      "Decoded sentence: . . <END>\n",
      "--------------------------------------------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Input sentence: Duck!\n",
      "Decoded sentence: . . <END>\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Preprocess the data\n",
    "    print(\"Loading and preprocessing data...\")\n",
    "    input_texts, target_texts, input_tokens, target_tokens = load_data(DATA_PATH, NUM_LINES)\n",
    "    (encoder_input_data, decoder_input_data, decoder_target_data,\n",
    "     input_features_dict, target_features_dict, reverse_target_features_dict,\n",
    "     max_encoder_seq_length, max_decoder_seq_length) = vectorize_data(input_texts, target_texts, input_tokens, target_tokens)\n",
    "\n",
    "    num_encoder_tokens = len(input_tokens)\n",
    "    num_decoder_tokens = len(target_tokens)\n",
    "    print(f\"Number of samples: {len(input_texts)}\")\n",
    "    print(f\"Number of unique input tokens: {num_encoder_tokens}\")\n",
    "    print(f\"Number of unique output tokens: {num_decoder_tokens}\")\n",
    "    print(f\"Max sequence length for inputs: {max_encoder_seq_length}\")\n",
    "    print(f\"Max sequence length for outputs: {max_decoder_seq_length}\\n\")\n",
    "\n",
    "    # Build the training model\n",
    "    print(\"Building the training model...\")\n",
    "    training_model, encoder_inputs, decoder_inputs, decoder_lstm, decoder_dense = build_training_model(num_encoder_tokens, num_decoder_tokens, LATENT_DIM)\n",
    "    training_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    training_model.summary()\n",
    "    \n",
    "    # Setup callbacks for early stopping and saving the best model\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=5, verbose=1),\n",
    "        ModelCheckpoint('training_model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "    ]\n",
    "    \n",
    "    # Train the model\n",
    "    print(\"\\nTraining the model...\")\n",
    "    training_model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "                       batch_size=BATCH_SIZE,\n",
    "                       epochs=EPOCHS,\n",
    "                       validation_split=0.2,\n",
    "                       callbacks=callbacks)\n",
    "    \n",
    "    # Load the best saved model\n",
    "    print(\"\\nLoading the best model...\")\n",
    "    model = load_model('training_model.h5')\n",
    "    \n",
    "    # Build inference models\n",
    "    encoder_model, decoder_model = build_inference_models(model, LATENT_DIM, num_encoder_tokens, num_decoder_tokens)\n",
    "    \n",
    "    # Testing: Decode some sequences and display\n",
    "    print(\"\\nDecoding test sequences...\\n\")\n",
    "    for seq_index in range(min(10, len(input_texts))):\n",
    "        test_input = encoder_input_data[seq_index: seq_index + 1]\n",
    "        decoded_sentence = decode_sequence(test_input, encoder_model, decoder_model,\n",
    "                                           target_features_dict, reverse_target_features_dict,\n",
    "                                           max_decoder_seq_length, num_decoder_tokens, LATENT_DIM)\n",
    "        print(\"Input sentence:\", input_texts[seq_index])\n",
    "        print(\"Decoded sentence:\", decoded_sentence)\n",
    "        print('-' * 50)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08388cce-5104-4f25-8751-1917efb6bfd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
