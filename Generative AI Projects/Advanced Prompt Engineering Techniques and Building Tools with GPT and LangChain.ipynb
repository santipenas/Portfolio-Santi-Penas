{"cells":[{"source":"# Advanced Prompt Engineering Techniques and Building Tools with GPT and LangChain","metadata":{},"id":"a6d014ee-e3b7-409c-948b-ac0152f49563","cell_type":"markdown"},{"source":"### Prompt Engineering with GPT and LangChain\n\nLangChain is a powerful framework designed to facilitate prompt engineering and the seamless integration of generative AI capabilities into applications or data platforms. This framework offers a wide array of functionalities, some of which will be introduced in later modules. For now, we will start with a gentle introduction to some of the fundamental and easy-to-understand concepts within LangChain.\n\nIn this project, you will build an AI agent that leverages Python and GPT to perform sentiment analysis on financial headlines. This project is designed to showcase your skills as a generative AI engineer and can be a valuable addition to your portfolio.\n\n## Project Overview\n\n### Objectives\n- **Set Up OpenAI Developer Account**: Learn how to create and configure an OpenAI developer account and integrate it with your development environment.\n- **Interact with OpenAI Models**: Use the LangChain framework to interact with OpenAI models, enabling you to harness the power of GPT for various tasks.\n- **Prompt Templates**: Create reusable and dynamic prompt templates to streamline the process of generating prompts for different tasks.\n- **LLM Chains**: Understand and implement LLM (Large Language Model) chains to manage complex workflows involving multiple AI models.\n- **Output Parsing**: Automatically parse the output of an LLM to make it usable for downstream applications.\n- **LangChain Agents and Tools**: Work with LangChain agents and tools to build more sophisticated AI applications.\n- **Content Moderation**: Utilize the OpenAI Moderation API to filter explicit content, ensuring that your application adheres to content guidelines.\n\n### Workflow\n1. **Environment Setup**\n   - Install necessary libraries and dependencies.\n   - Configure API keys and authentication for OpenAI.\n\n2. **Data Preparation**\n   - Load and preprocess the sample datasets: `financial_headlines.txt` and `reddit_comments.txt`.\n   - Understand the structure and content of the datasets to tailor the AI models accordingly.\n\n3. **Prompt Engineering**\n   - Design and implement prompt templates that can dynamically generate prompts based on input data.\n   - Test and refine prompts to ensure they produce the desired output.\n\n4. **Model Interaction**\n   - Use LangChain to interact with OpenAI models.\n   - Implement functions to send prompts to the models and receive responses.\n\n5. **LLM Chains**\n   - Create and manage LLM chains to handle complex workflows.\n   - Chain multiple models together to perform multi-step tasks.\n\n6. **Output Parsing**\n   - Develop methods to parse the model outputs.\n   - Ensure the parsed data is in a format suitable for further analysis or downstream applications.\n\n7. **Agent and Tool Integration**\n   - Integrate LangChain agents and tools to enhance the functionality of your AI application.\n   - Implement additional tools as needed to support specific tasks.\n\n8. **Content Moderation**\n   - Use the OpenAI Moderation API to filter out explicit content.\n   - Ensure your application complies with content guidelines and maintains a high standard of quality.\n\n### Technology Stack\n- **Python**: The primary programming language used for this project.\n- **LangChain**: The framework used to facilitate prompt engineering and model interaction.\n- **OpenAI GPT**: The generative AI model used for sentiment analysis and other tasks.\n- **OpenAI Moderation API**: Used for content moderation to filter explicit content.\n- **Jupyter Notebook**: The development environment for writing and testing code.\n\n### Sample Datasets\nFor this project, we are using two small samples:\n- `financial_headlines.txt`: A sample dataset containing financial headlines.\n- `reddit_comments.txt`: A sample dataset containing Reddit comments.\n\nThese 5-6 line samples are kept short to simplify evaluation, but the same code and prompt engineering techniques can scale to much larger datasets.\n\n## Conclusion\nBy the end of this project, you will have a robust understanding of how to use LangChain and GPT for prompt engineering and sentiment analysis. This project will not only enhance your skills but also serve as a strong portfolio piece demonstrating your capabilities as a generative AI engineer.","metadata":{},"id":"9a610d9c-089e-4b41-803d-17024f68c51a","cell_type":"markdown"},{"source":"## Setup","metadata":{},"id":"833b24bb-221d-4d34-9927-8b83496fb65d","cell_type":"markdown"},{"source":"We need to install a few packages, one of which being the `langchain` package. This is currently being developed quickly, sometimes with breaking changes, so we fix the version.\n\n`langchain` depends on a recent version of `typing_extensions`, so we need to update that package, again fixing the version.","metadata":{},"id":"2c4850c8-97f7-4389-96c6-9f44ecbfd06d","cell_type":"markdown"},{"source":"Run the following code to install `openai`, `langchain`, `typing_extensions` and `pandas`.","metadata":{},"id":"115b1f8e-55a2-471e-8c45-0eaf3e685a44","cell_type":"markdown"},{"source":"# Install the openai package, locked to version 1.27\n!pip install openai==1.27\n\n# Install the langchain package, locked to version 0.1.19\n!pip install langchain==0.1.19\n\n# Install the langchain-openai package, locked to version 0.1.6\n!pip install langchain-openai==0.1.6\n\n# Install the langchain-experimental package, locked to version 0.0.58\n!pip install langchain-experimental==0.0.58\n\n# Update the typing_extensions package, locked to version 4.11.0\n!pip install typing_extensions==4.11.0","metadata":{"executionCancelledAt":null,"executionTime":17601,"lastExecutedAt":1749074343803,"lastExecutedByKernel":"6915a89c-0b39-433b-a056-35cfb360a427","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Install the openai package, locked to version 1.27\n!pip install openai==1.27\n\n# Install the langchain package, locked to version 0.1.19\n!pip install langchain==0.1.19\n\n# Install the langchain-openai package, locked to version 0.1.6\n!pip install langchain-openai==0.1.6\n\n# Install the langchain-experimental package, locked to version 0.0.58\n!pip install langchain-experimental==0.0.58\n\n# Update the typing_extensions package, locked to version 4.11.0\n!pip install typing_extensions==4.11.0","outputsMetadata":{"0":{"height":437,"type":"stream"}}},"cell_type":"code","id":"9f6478ea-79de-47f4-988b-5b2905d82d71","outputs":[{"output_type":"stream","name":"stdout","text":"Defaulting to user installation because normal site-packages is not writeable\nCollecting openai==1.27\n  Downloading openai-1.27.0-py3-none-any.whl.metadata (21 kB)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.27) (4.8.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.27) (1.7.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.27) (0.27.2)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.27) (2.7.1)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.27) (1.3.1)\nRequirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.27) (4.67.1)\nRequirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai==1.27) (4.12.2)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.27) (1.2.2)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.27) (3.10)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.27) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.27) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.27) (0.14.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.27) (0.7.0)\nRequirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.27) (2.18.2)\nDownloading openai-1.27.0-py3-none-any.whl (314 kB)\nInstalling collected packages: openai\nSuccessfully installed openai-1.27.0\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\nDefaulting to user installation because normal site-packages is not writeable\nCollecting langchain==0.1.19\n  Downloading langchain-0.1.19-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (6.0.1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (2.0.38)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (3.11.12)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (4.0.3)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (0.6.7)\nRequirement already satisfied: langchain-community<0.1,>=0.0.38 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (0.0.38)\nRequirement already satisfied: langchain-core<0.2.0,>=0.1.52 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (0.1.53)\nRequirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (0.0.2)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (0.1.147)\nRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (1.26.4)\nRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (2.7.1)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (2.32.3)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.19) (8.5.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.19) (1.18.3)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.19) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.19) (0.9.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.52->langchain==0.1.19) (1.33)\nRequirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.52->langchain==0.1.19) (23.2)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.19) (0.27.2)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.19) (3.10.15)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.19) (1.0.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.19) (0.7.0)\nRequirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.19) (2.18.2)\nRequirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.19) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.19) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.19) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.19) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.19) (2025.1.31)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.19) (3.1.1)\nRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.19) (4.8.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.19) (1.0.7)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.19) (1.3.1)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.19) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain==0.1.19) (3.0.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.19) (1.0.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.19) (1.2.2)\nDownloading langchain-0.1.19-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: langchain\nSuccessfully installed langchain-0.1.19\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\nDefaulting to user installation because normal site-packages is not writeable\nCollecting langchain-openai==0.1.6\n  Downloading langchain_openai-0.1.6-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: langchain-core<0.2.0,>=0.1.46 in /usr/local/lib/python3.10/dist-packages (from langchain-openai==0.1.6) (0.1.53)\nRequirement already satisfied: openai<2.0.0,>=1.24.0 in /home/repl/.local/lib/python3.10/site-packages (from langchain-openai==0.1.6) (1.27.0)\nRequirement already satisfied: tiktoken<1,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-openai==0.1.6) (0.7.0)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (6.0.1)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (1.33)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (0.1.147)\nRequirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (23.2)\nRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (2.7.1)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (8.5.0)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (4.8.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (1.7.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (0.27.2)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (1.3.1)\nRequirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (4.67.1)\nRequirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (4.12.2)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai==0.1.6) (2023.12.25)\nRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai==0.1.6) (2.32.3)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (1.2.2)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (3.10)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai==0.1.6) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (3.0.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (3.10.15)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (1.0.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (0.7.0)\nRequirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.46->langchain-openai==0.1.6) (2.18.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai==0.1.6) (3.4.1)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai==0.1.6) (2.3.0)\nDownloading langchain_openai-0.1.6-py3-none-any.whl (34 kB)\nInstalling collected packages: langchain-openai\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nembedchain 0.1.113 requires langchain-openai<0.2.0,>=0.1.7, but you have langchain-openai 0.1.6 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed langchain-openai-0.1.6\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\nDefaulting to user installation because normal site-packages is not writeable\nCollecting langchain-experimental==0.0.58\n  Downloading langchain_experimental-0.0.58-py3-none-any.whl.metadata (2.1 kB)\nRequirement already satisfied: langchain<0.2.0,>=0.1.17 in /home/repl/.local/lib/python3.10/site-packages (from langchain-experimental==0.0.58) (0.1.19)\nRequirement already satisfied: langchain-core<0.2.0,>=0.1.52 in /usr/local/lib/python3.10/dist-packages (from langchain-experimental==0.0.58) (0.1.53)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (6.0.1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (2.0.38)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (3.11.12)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (4.0.3)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (0.6.7)\nRequirement already satisfied: langchain-community<0.1,>=0.0.38 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (0.0.38)\nRequirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (0.0.2)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (0.1.147)\nRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (1.26.4)\nRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (2.7.1)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (2.32.3)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (8.5.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.52->langchain-experimental==0.0.58) (1.33)\nRequirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.52->langchain-experimental==0.0.58) (23.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (1.18.3)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (0.9.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain-experimental==0.0.58) (3.0.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (0.27.2)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (3.10.15)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (1.0.0)\nRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (0.7.0)\nRequirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (2.18.2)\nRequirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (2025.1.31)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (3.1.1)\nRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (4.8.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (1.0.7)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (1.3.1)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (0.14.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (1.0.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.17->langchain-experimental==0.0.58) (1.2.2)\nDownloading langchain_experimental-0.0.58-py3-none-any.whl (199 kB)\nInstalling collected packages: langchain-experimental\nSuccessfully installed langchain-experimental-0.0.58\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\nDefaulting to user installation because normal site-packages is not writeable\nCollecting typing_extensions==4.11.0\n  Downloading typing_extensions-4.11.0-py3-none-any.whl.metadata (3.0 kB)\nDownloading typing_extensions-4.11.0-py3-none-any.whl (34 kB)\nInstalling collected packages: typing_extensions\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nembedchain 0.1.113 requires langchain-openai<0.2.0,>=0.1.7, but you have langchain-openai 0.1.6 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed typing_extensions-4.11.0\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"}],"execution_count":2},{"source":"For this project, we need first need to load the openai and os packages to set the API key from the environment variables you just created.","metadata":{},"id":"be271ab6-b977-45b3-8b5d-f86b73e9fd2b","cell_type":"markdown"},{"source":"- Import the `os` package.\n- Import the `openai` package.\n- Set `openai.api_key` to the `OPENAI_API_KEY` environment variable.","metadata":{},"id":"30c2c737-4fd2-4a6a-b9c0-710118699d86","cell_type":"markdown"},{"source":"# Import the os package.\nimport os\n\n# Import the openai package.\nimport openai\n\n# Set openai.api_key to the OPENAI_API_KEY environment variable.\nopenai.api_key = os.environ[\"OPENAI_API_KEY\"]","metadata":{"executionCancelledAt":null,"executionTime":2155,"lastExecutedAt":1749074345960,"lastExecutedByKernel":"6915a89c-0b39-433b-a056-35cfb360a427","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import the os package.\nimport os\n\n# Import the openai package.\nimport openai\n\n# Set openai.api_key to the OPENAI_API_KEY environment variable.\nopenai.api_key = os.environ[\"OPENAI_API_KEY\"]"},"id":"2d301524-67c0-4894-8e2a-72787de3c9bc","cell_type":"code","execution_count":3,"outputs":[]},{"source":"For the `langchain` package, let's start by importing its `OpenAI` and `ChatOpenAI` classes, which are used to interact with completion models and chat completion models respectively.\n\nCompletion models, such as GPT-1, GPT-2, GPT-3, and GPT-3.5, work as advanced autocomplete models. Given a certain snippet of text as input, they will complete the text until a certain point. This could be either an end-of-sequence token (a natural way of stopping), the model reaching its maximum token limit for outputs, and so on.\n\nChat completion models, such as GPT-3.5-Turbo (the ChatGPT model) and GPT-4, are designed for conversational use. These models are typically more fine-tuned for conversations, keep a prompt/conversation history, and allow access to a system message, which we can use as a meta prompt to define a role, a tone of voice, a scope, etc.\n\nCompletion models and chat completion models tend to work with different classes and functions in the SDK. For that reason, we will start by importing both classes.","metadata":{},"id":"8fa361c0-da75-42f5-84c7-142ed2307c20","cell_type":"markdown"},{"source":"- Import `OpenAI` and `ChatOpenAI` from `langchain_openai`.\n- From the `langchain.prompts` module, import the `PromptTemplate` and `ChatPromptTemplate` classes.\n- From the `langchain.output_parsers` module, import the `CommaSeparatedListOutputParser` class.\n- From the `langchain_experimental.agents.agent_toolkits` module, import `create_python_agent`.\n- From the `langchain_experimental.tools.python.tool` module, import `PythonREPLTool`.","metadata":{},"id":"f18c0e9a-dcc2-4862-895b-e6ecb4347e5f","cell_type":"markdown"},{"source":"# From langchain_openai, import OpenAI, ChatOpenAI\nfrom langchain_openai import OpenAI, ChatOpenAI\n\n# From langchain.prompts, import PromptTemplate, ChatPromptTemplate\nfrom langchain.prompts import PromptTemplate, ChatPromptTemplate\n\n# From langchain.output_parsers, import CommaSeparatedListOutputParser\nfrom langchain.output_parsers import CommaSeparatedListOutputParser\n\n# From langchain_experimental.agents.agent_toolkits, import create_python_agent\nfrom langchain_experimental.agents.agent_toolkits import create_python_agent\n\n# From langchain_experimental.tools.python.tool, import PythonREPLTool\nfrom langchain_experimental.tools.python.tool import PythonREPLTool","metadata":{"executionCancelledAt":null,"executionTime":894,"lastExecutedAt":1749074346856,"lastExecutedByKernel":"6915a89c-0b39-433b-a056-35cfb360a427","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# From langchain_openai, import OpenAI, ChatOpenAI\nfrom langchain_openai import OpenAI, ChatOpenAI\n\n# From langchain.prompts, import PromptTemplate, ChatPromptTemplate\nfrom langchain.prompts import PromptTemplate, ChatPromptTemplate\n\n# From langchain.output_parsers, import CommaSeparatedListOutputParser\nfrom langchain.output_parsers import CommaSeparatedListOutputParser\n\n# From langchain_experimental.agents.agent_toolkits, import create_python_agent\nfrom langchain_experimental.agents.agent_toolkits import create_python_agent\n\n# From langchain_experimental.tools.python.tool, import PythonREPLTool\nfrom langchain_experimental.tools.python.tool import PythonREPLTool"},"cell_type":"code","id":"8874bb89-4379-4025-aa54-0870c1aa50fb","outputs":[],"execution_count":4},{"source":"Take a look of our LangChain version instaled:","metadata":{},"cell_type":"markdown","id":"4af46ec3-1ba2-462d-afa7-042a18910256"},{"source":"pip show langchain","metadata":{"executionCancelledAt":null,"executionTime":2705,"lastExecutedAt":1749074349563,"lastExecutedByKernel":"6915a89c-0b39-433b-a056-35cfb360a427","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"pip show langchain","outputsMetadata":{"0":{"height":269,"type":"stream"}}},"cell_type":"code","id":"581973b4-c4f2-4503-8997-980071c066ef","outputs":[{"output_type":"stream","name":"stdout","text":"Name: langchain\nVersion: 0.1.19\nSummary: Building applications with LLMs through composability\nHome-page: https://github.com/langchain-ai/langchain\nAuthor: \nAuthor-email: \nLicense: MIT\nLocation: /home/repl/.local/lib/python3.10/site-packages\nRequires: aiohttp, async-timeout, dataclasses-json, langchain-community, langchain-core, langchain-text-splitters, langsmith, numpy, pydantic, PyYAML, requests, SQLAlchemy, tenacity\nRequired-by: crewai, embedchain, langchain-experimental\nNote: you may need to restart the kernel to use updated packages.\n"}],"execution_count":5},{"source":"## Import the Financial News Headlines Data","metadata":{},"id":"303fc31e-5f83-41a3-a078-e929a11e8bf0","cell_type":"markdown"},{"source":"A small sample of financial headlines is stored in `financial_headlines.txt`.\n\nOur first step is to read in the text file and store the headlines in a Python list.","metadata":{},"id":"b1c1b04e-0de7-4050-950e-4f64dfc6a58d","cell_type":"markdown"},{"source":"\nImport the text file to a Python list.\n\n- Open `financial_headlines.txt` for reading.\n- Read in the lines using the `.readlines()` method. Assign to `headlines`.\n- Print the sample headlines.","metadata":{},"id":"10678d41-3b1c-4471-9e4c-9b1f32ea038f","cell_type":"markdown"},{"source":"# Open the text file and read its lines.\nwith open(\"financial_headlines.txt\", \"r\") as file:\n    headlines  = file.readlines()\n\n# Print all headlines.\nheadlines","metadata":{"executionCancelledAt":null,"executionTime":49,"lastExecutedAt":1749074349612,"lastExecutedByKernel":"6915a89c-0b39-433b-a056-35cfb360a427","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Open the text file and read its lines.\nwith open(\"financial_headlines.txt\", \"r\") as file:\n    headlines  = file.readlines()\n\n# Print all headlines.\nheadlines","outputsMetadata":{"0":{"height":122,"type":"stream"}}},"id":"1b5638c5-9db0-4731-8170-e7b6c1a99697","cell_type":"code","execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":"[\"Finnish Aktia Group 's operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .\\n\",\n 'Finnish measuring equipment maker Vaisala Oyj HEL : VAIAS said today that its net loss widened to EUR4 .8 m in the first half of 2010 from EUR2 .3 m in the corresponding period a year earlier .\\n',\n 'Finnish pharmaceuticals company Orion reports profit before taxes of EUR 70.0 mn in the third quarter of 2010 , up from EUR 54.9 mn in the corresponding period in 2009 .\\n',\n 'Tiimari , the Finnish retailer , reported to have geenrated quarterly revenues totalling EUR 1.3 mn in the 4th quarter 2009 , up from EUR 0.3 mn loss in 2008 .\\n',\n \"Finnish Metso Paper has been awarded a contract for the rebuild of Sabah Forest Industries ' ( SFI ) pulp mill in Sabah , Malaysia .\\n\",\n 'Finnish Outokumpu Technology has been awarded several new grinding technology contracts .']"},"metadata":{},"execution_count":6}]},{"source":"The headlines seem to a bit of whitespace preceding the punctuation, but this does not influence the performance of our large language model.\nYou can also see that every headline ends with a new line (`\\n`).\n\nWe can quickly strip the `\\n` from the end of each headline, as this might improve visibility later down the line, when printing these headlines in a dataframe. ","metadata":{},"id":"7c0a4789-58a1-4546-bb39-c5b540eb8559","cell_type":"markdown"},{"source":"\nStrip the `\\n` character from the end of every news headline.\n\n- Loop through `headlines` and use the `.strip()` method to remove the `\\n` character from each line.\n- Print the result.","metadata":{},"id":"5c7b522e-32b6-4818-9834-f0c2bbf7f230","cell_type":"markdown"},{"source":"# Strip the new line character from all headlines.\nheadlines = [line.strip(\"\\n\") for line in headlines] \n\n# Print all headlines.\nheadlines","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1749074349660,"lastExecutedByKernel":"6915a89c-0b39-433b-a056-35cfb360a427","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Strip the new line character from all headlines.\nheadlines = [line.strip(\"\\n\") for line in headlines] \n\n# Print all headlines.\nheadlines","outputsMetadata":{"0":{"height":122,"type":"stream"}}},"id":"980f8d06-4d48-4fb9-9cab-ac66a8371910","cell_type":"code","execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":"[\"Finnish Aktia Group 's operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .\",\n 'Finnish measuring equipment maker Vaisala Oyj HEL : VAIAS said today that its net loss widened to EUR4 .8 m in the first half of 2010 from EUR2 .3 m in the corresponding period a year earlier .',\n 'Finnish pharmaceuticals company Orion reports profit before taxes of EUR 70.0 mn in the third quarter of 2010 , up from EUR 54.9 mn in the corresponding period in 2009 .',\n 'Tiimari , the Finnish retailer , reported to have geenrated quarterly revenues totalling EUR 1.3 mn in the 4th quarter 2009 , up from EUR 0.3 mn loss in 2008 .',\n \"Finnish Metso Paper has been awarded a contract for the rebuild of Sabah Forest Industries ' ( SFI ) pulp mill in Sabah , Malaysia .\",\n 'Finnish Outokumpu Technology has been awarded several new grinding technology contracts .']"},"metadata":{},"execution_count":7}]},{"source":"## Setting up Prompt Templates","metadata":{},"id":"f389f489-eddd-45c0-84d7-44dd8f9ca5b3","cell_type":"markdown"},{"source":"- Create a Prompt Template to analyze financial sentiment.\n- Create a `PromptTemplate` object by using its `.from_template()` method. Assign to `prompt_template`.\n- For the template argument, use:\n\n```\n\"Analyze the following financial headline for sentiment: {headline}\"\n```\n\n- Format the prompt using its `.format()` method. Let's use our first headline as input. Assign to `formatted_prompt`.\n- Print the formatted prompt.","metadata":{},"id":"82de02d9-6a87-4ea1-9b56-c3f03b463748","cell_type":"markdown"},{"source":"# Create a dynamic template to analyze a single headline.\nprompt_template = PromptTemplate.from_template(\n    \"Analyze the following financial headline for sentiment: {headline}\"\n)\n\n# Format the prompt template on the first headline of the dataset.\nformatted_prompt = prompt_template.format(headline = headlines[0])\n\n# Print the formatted template.\nformatted_prompt","metadata":{"executionCancelledAt":null,"executionTime":47,"lastExecutedAt":1749074349707,"lastExecutedByKernel":"6915a89c-0b39-433b-a056-35cfb360a427","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Create a dynamic template to analyze a single headline.\nprompt_template = PromptTemplate.from_template(\n    \"Analyze the following financial headline for sentiment: {headline}\"\n)\n\n# Format the prompt template on the first headline of the dataset.\nformatted_prompt = prompt_template.format(headline = headlines[0])\n\n# Print the formatted template.\nformatted_prompt"},"id":"e5c74f6d-fad2-4a52-a2e4-653768d33c33","cell_type":"code","execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":"\"Analyze the following financial headline for sentiment: Finnish Aktia Group 's operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .\""},"metadata":{},"execution_count":8}]},{"source":"- Define a system message as follows and assign to `system_message`.\n\n```\n\"\"\"You are performing sentiment analysis on news headlines regarding financial analysis. \nThis sentiment is to be used to advice financial analysts. \nThe format of the output has to be consistent. \nThe output is strictly limited to any of the following options: [positive, negative, neutral].\"\"\"\n```\n\n- Instantiate a new `ChatPromptTemplate` using its `.from_messages()` method. Assign to `chat_template`.\n    - This method will take a list of tuples as input. We need two tuples, one for the system message and one for the human message. To distinguish the two, the first element of the tuple is either `\"system\"` or `\"human\"`.\n    - The second element of the tuple is the actual message, as string. For the system message, you can use the `system_message`variable. For the human message, we can reuse the same message as before (including the input variable `{headlines}`).\n    \n- Format the template using its `.format_messages()` method. Let's use our first headline again. Assign to `formatted_chat_template`.\n- Print the formatted template.","metadata":{},"id":"054ac0a5-48d9-46a8-bc27-412280ea0eee","cell_type":"markdown"},{"source":"# Define the system message.\nsystem_message = \"\"\"You are performing sentiment analysis on news headlines regarding financial analysis. \nThis sentiment is to be used to advice financial analysts. \nThe format of the output has to be consistent. \nThe output is strictly limited to any of the following options: [positive, negative, neutral].\"\"\"\n\n# Initialize a new ChatPromptTemplate with a system message and human message.\nchat_template = ChatPromptTemplate.from_messages([\n    (\"system\", system_message),\n    (\"human\", \"Analyze the following financial headline for sentiment: {headline}\")\n])\n\n# Format the ChatPromptTemplate.\nformatted_chat_template = chat_template.format(headline = headlines[0]) # we could also use the  .format_messages() methods instead the .format()\n\n# Print the formatted template.\nformatted_chat_template","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1749074349759,"lastExecutedByKernel":"6915a89c-0b39-433b-a056-35cfb360a427","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define the system message.\nsystem_message = \"\"\"You are performing sentiment analysis on news headlines regarding financial analysis. \nThis sentiment is to be used to advice financial analysts. \nThe format of the output has to be consistent. \nThe output is strictly limited to any of the following options: [positive, negative, neutral].\"\"\"\n\n# Initialize a new ChatPromptTemplate with a system message and human message.\nchat_template = ChatPromptTemplate.from_messages([\n    (\"system\", system_message),\n    (\"human\", \"Analyze the following financial headline for sentiment: {headline}\")\n])\n\n# Format the ChatPromptTemplate.\nformatted_chat_template = chat_template.format(headline = headlines[0]) # we could also use the  .format_messages() methods instead the .format()\n\n# Print the formatted template.\nformatted_chat_template"},"id":"2d621445-3804-442d-8040-8405c6c9c83f","cell_type":"code","execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":"\"System: You are performing sentiment analysis on news headlines regarding financial analysis. \\nThis sentiment is to be used to advice financial analysts. \\nThe format of the output has to be consistent. \\nThe output is strictly limited to any of the following options: [positive, negative, neutral].\\nHuman: Analyze the following financial headline for sentiment: Finnish Aktia Group 's operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .\""},"metadata":{},"execution_count":9}]},{"source":"## Setting up LLM Chains","metadata":{},"id":"ec62e063-c2bf-42c9-bb54-f774e3f13ff2","cell_type":"markdown"},{"source":"Create an LLM chain for a completion model.\n- Define an `OpenAI()` client model. Assign to `client`.\n- Pipe the prompt template to the client. Assign to `completion_chain`.\n- Invoke `completion_chain`, setting the headline variable to the first element of the `headlines` list.","metadata":{},"id":"a597b3fb-9710-4054-a0cc-a0541cfb3f4a","cell_type":"markdown"},{"source":"#import LLMChain class\nfrom langchain.chains import LLMChain\n\n# Define a client model. Assign to client.\nclient = OpenAI()\n\n# Pipe the prompt template to the client. Assign to completion_chain.\ncompletion_chain = LLMChain(llm= client, prompt = prompt_template)\n\n# Invoke completion_chain, setting the headline variable to the first headline\ncompletion_chain.invoke({\"headline\": headlines[0]})  # we can also use .run method instead of .invoke()","metadata":{"executionCancelledAt":null,"executionTime":1147,"lastExecutedAt":1749074350907,"lastExecutedByKernel":"6915a89c-0b39-433b-a056-35cfb360a427","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#import LLMChain class\nfrom langchain.chains import LLMChain\n\n# Define a client model. Assign to client.\nclient = OpenAI()\n\n# Pipe the prompt template to the client. Assign to completion_chain.\ncompletion_chain = LLMChain(llm= client, prompt = prompt_template)\n\n# Invoke completion_chain, setting the headline variable to the first headline\ncompletion_chain.invoke({\"headline\": headlines[0]})  # we can also use .run method instead of .invoke()"},"id":"234126d2-0e6a-4286-8fd9-2ec95eb5a566","cell_type":"code","execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning:\n\nThe class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n\n"},{"output_type":"execute_result","data":{"text/plain":"{'headline': \"Finnish Aktia Group 's operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .\",\n 'text': '\\n\\nPositive'}"},"metadata":{},"execution_count":10}]},{"source":"Now let's do the same, using a chat completion model.","metadata":{},"id":"20424b97-c01c-4786-9460-beae26fb8a35","cell_type":"markdown"},{"source":"- Define a chat client model. Assign to `chat`.\n- Pipe the chat template to the client. Assign to `chat_chain`.\n- Invoke `chat_chain`, setting the headline to the first element of `headlines`. In the additioanl arguments, set `system_message` to `system_message`.","metadata":{},"id":"e834ad2f-299b-4834-8e05-56eb0b67e99e","cell_type":"markdown"},{"source":"# Define a chat client model. Assign to chat.\nchat = ChatOpenAI()\n\n# Pipe the chat template to the client. Assign to chat_chain.\nchat_chain = LLMChain(llm=chat, prompt=chat_template)  # chat_chain = chat | chat_template\n\n# Invoke chat_chain, setting headline to the first headline and using system_message\nchat_chain.invoke({\"headline\": headlines[0]}, {\"system_message\": system_message})","metadata":{"executionCancelledAt":null,"executionTime":677,"lastExecutedAt":1749074351584,"lastExecutedByKernel":"6915a89c-0b39-433b-a056-35cfb360a427","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define a chat client model. Assign to chat.\nchat = ChatOpenAI()\n\n# Pipe the chat template to the client. Assign to chat_chain.\nchat_chain = LLMChain(llm=chat, prompt=chat_template)  # chat_chain = chat | chat_template\n\n# Invoke chat_chain, setting headline to the first headline and using system_message\nchat_chain.invoke({\"headline\": headlines[0]}, {\"system_message\": system_message})"},"id":"00a8db2b-fd72-421c-9e17-82a47ee460b5","cell_type":"code","execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":"{'headline': \"Finnish Aktia Group 's operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .\",\n 'text': 'The sentiment of the financial headline is positive.'}"},"metadata":{},"execution_count":11}]},{"source":"## Extracting Company Names with the Output Parser","metadata":{},"id":"b55de8b3-7e57-4fcb-b160-462b22828122","cell_type":"markdown"},{"source":"Output parsing is a very useful feature in Langchain when integrating LLM outputs into your application. The output parser can automatically transform the output of the GPT-model to numerous data types, such as lists, datetimes, JSONs and so on.\n\nIn this example, we will ask the GPT-model to extract the company name from every headline and instantly assign them to a Python list.\n\nAs we want to combine sentiment with the company name later, we will limit the output to one name per headline.\n\nIn order to format the output as a Python list, we can make use of the `CommaSeparatedListOutputParser` class in Langchain.","metadata":{},"id":"b5c74f27-1a7a-43f8-b0c1-04bfc9611f0f","cell_type":"markdown"},{"source":"Create an output parser and a formatted prompt template to extract company names from multiple headlines.\n- Instantiate a new `CommaSeparatedListOutputParser` and assign to `output_parser`.\n- To retrieve the parsing instructions from the output parser, we can use its `.get_format_instructions()` method. Assign this to `format_instructions`.\n- Let's instantiate a new `PromptTemplate`. This time we won't use its `.from_template()` method. When calling `PromptTemplate()` with the output parser, we need to pass three arguments:\n    - `template`: here we can use the following string; \n```\n\"List all the company names from the following headlines, limited to one name per headline: {headlines}.\\n{format_instructions}\"\n```\n\n- `input_variables`: This is a list of strings containing the input variables that are required. In our case, this is only `\"headlines\"`.\n- `partial_variables`: Here we pass along a dictionary with the key being `\"format_instructions\"` and the value being the `format_instructions` variable we created earlier.\n- Format the prompt template using the entire `headlines` list.","metadata":{},"id":"60d62a05-8c14-4d02-b6ed-1d896f222724","cell_type":"markdown"},{"source":"# Instantiate the output parser.\noutput_parser = CommaSeparatedListOutputParser()\n\n# Get the format instructions from the output parser.\nformat_instructions = output_parser.get_format_instructions()\n\n# Instantiate a new prompt template with the format instructions.\ncompany_name_template = PromptTemplate(\n    template = \"List all the company names from the following headlines, limited to one name per headline: {headlines}.\\n{format_instructions}\",\n    input_variables = [\"headlines\"],\n    partial_variables = {\"format_instructions\": format_instructions},\n)\n\n# Format the prompt using all headlines.\ncompany_name_template_formated = company_name_template.format(headlines=headlines)\n\nprint(company_name_template_formated)","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1749074351632,"lastExecutedByKernel":"6915a89c-0b39-433b-a056-35cfb360a427","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Instantiate the output parser.\noutput_parser = CommaSeparatedListOutputParser()\n\n# Get the format instructions from the output parser.\nformat_instructions = output_parser.get_format_instructions()\n\n# Instantiate a new prompt template with the format instructions.\ncompany_name_template = PromptTemplate(\n    template = \"List all the company names from the following headlines, limited to one name per headline: {headlines}.\\n{format_instructions}\",\n    input_variables = [\"headlines\"],\n    partial_variables = {\"format_instructions\": format_instructions},\n)\n\n# Format the prompt using all headlines.\ncompany_name_template_formated = company_name_template.format(headlines=headlines)\n\nprint(company_name_template_formated)","outputsMetadata":{"0":{"height":185,"type":"stream"}}},"id":"6cac36e4-9d98-414e-8204-848c299a3457","cell_type":"code","execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":"List all the company names from the following headlines, limited to one name per headline: [\"Finnish Aktia Group 's operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .\", 'Finnish measuring equipment maker Vaisala Oyj HEL : VAIAS said today that its net loss widened to EUR4 .8 m in the first half of 2010 from EUR2 .3 m in the corresponding period a year earlier .', 'Finnish pharmaceuticals company Orion reports profit before taxes of EUR 70.0 mn in the third quarter of 2010 , up from EUR 54.9 mn in the corresponding period in 2009 .', 'Tiimari , the Finnish retailer , reported to have geenrated quarterly revenues totalling EUR 1.3 mn in the 4th quarter 2009 , up from EUR 0.3 mn loss in 2008 .', \"Finnish Metso Paper has been awarded a contract for the rebuild of Sabah Forest Industries ' ( SFI ) pulp mill in Sabah , Malaysia .\", 'Finnish Outokumpu Technology has been awarded several new grinding technology contracts .'].\nYour response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\n"}]},{"source":"Now that we have a template with format instructions ready, let's send it to a GPT-model and look at the output. We want to run these kinds of tasks with the temperature parameter of the large language model set to zero, as this maximizes precision. \n\nWe tend to distinguish tasks that either require precision or creativity. When we are looking for correctness in the answer (e.g. when generating code) we aim for high precision (by lowering temperature) whereas when generating ideas or content, we might prefer more creativity (by increasing temperature). A simplified explanation of the *temperature* of a large language model is its randomness. When temperature is set to 0, we will get the exact same output, given the same inputs.","metadata":{},"id":"54576b7b-2048-49f6-939c-ced2c8a834d9","cell_type":"markdown"},{"source":"Create a new Langchain model, send over the template and inspect the parsed output.\n- Instantiate a new `OpenAI()` client model. Set the temperature to 0. Assign to `model`.\n- Invoke `model` on the formatted template. Assign to `_output`. The underscore preceding our variable name indicates that this is just a temporary variable, that will likely be overwritten many times.\n- Use the `.parse()` method of the output parser on the output of the model. Assign to `company_names`.\n- Print the data type of `company_names`.\n- Print the company names.","metadata":{},"id":"e00a6e04-c726-4dc1-a240-9f0b3291de28","cell_type":"markdown"},{"source":"<details>\n<summary>Code hints</summary>\n<p>\n\n- The temperature of the model can be set to 0 by using `OpenAI(temperature= )`.\n- We can get the data type of a variable by using `type(variable)`.\n\n</p>\n</details>","metadata":{},"id":"20ea561c-9b4f-4e6c-a630-eef71d2fc43d","cell_type":"markdown"},{"source":"# Instantiate a Langchain OpenAI Model object.\nmodel = OpenAI(temperature=0)\n\n# Invoke the model on the input.\n_output = model.invoke(company_name_template_formated)\n\n# Parse the output.\ncompany_names = output_parser.parse(_output)\n\n# Print the data type the parsed output.\nprint(type(company_names))\n\n# Print the output.\nprint(company_names)","metadata":{"executionCancelledAt":null,"executionTime":993,"lastExecutedAt":1749074352625,"lastExecutedByKernel":"6915a89c-0b39-433b-a056-35cfb360a427","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Instantiate a Langchain OpenAI Model object.\nmodel = OpenAI(temperature=0)\n\n# Invoke the model on the input.\n_output = model.invoke(company_name_template_formated)\n\n# Parse the output.\ncompany_names = output_parser.parse(_output)\n\n# Print the data type the parsed output.\nprint(type(company_names))\n\n# Print the output.\nprint(company_names)","outputsMetadata":{"0":{"height":59,"type":"stream"}}},"id":"f1dde4f8-ccb5-4bf0-a7d6-35f1a1f6e66a","cell_type":"code","execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":"<class 'list'>\n['Aktia Group', 'Vaisala Oyj', 'Orion', 'Tiimari', 'Metso Paper', 'Outokumpu Technology']\n"}]},{"source":"## Working with Agents and Tools","metadata":{},"id":"f8ab6d2c-87d1-4966-bac0-99f3ba39d195","cell_type":"markdown"},{"source":"Leveraging the agents and tools in LangChain is where the framework's value really starts to shine! But before we dive deeper into this concept, we need to understand MRKL prompts.","metadata":{},"id":"fa5daf04-5793-4fdc-a6d8-268430d7ab17","cell_type":"markdown"},{"source":"Before we continue with our financial analysis, let's create a quick example of how code can be ran using a Python agent. In this case, we will ask it to make a calculation (something that most large language models are not trained to do out-of-the-box).\n- Create a Python agent by calling the `create_python_agent()` function. Assign to `agent_executor`. This function takes three arguments:\n    - `llm`: here we can create a new `OpenAI()` model. Let's set the `temperature` to 0 and `max_tokens` to 1000.\n    - `tool`: here we instantiate a new `PythonREPLTool()`.\n    - `verbose`: set this to True so that can we see the prompt loop.\n- Invoke the agent using its `.invoke()` method. As an example, you can ask it: `\"What is the square root of 250? Round the answer down to 4 _decimals.\"`_","metadata":{},"id":"7234a5ec-0f44-4ca6-9d2e-0a983386b7e7","cell_type":"markdown"},{"source":"# Instantiate a Python agent, with the PythonREPLTool.\nagent_executor = create_python_agent(\n    llm = OpenAI(temperature = 0, max_tokens = 1000), \n    tool = PythonREPLTool(),\n    verbose = True  # to actually see the prompt loop im action\n)\n\n# Ask the agent for the solution of a mathematical equation.\nagent_executor.run(\"What is the square root of 250? Round the answer down to 4 decimals.\")","metadata":{"executionCancelledAt":null,"executionTime":3275,"lastExecutedAt":1749074355901,"lastExecutedByKernel":"6915a89c-0b39-433b-a056-35cfb360a427","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Instantiate a Python agent, with the PythonREPLTool.\nagent_executor = create_python_agent(\n    llm = OpenAI(temperature = 0, max_tokens = 1000), \n    tool = PythonREPLTool(),\n    verbose = True  # to actually see the prompt loop im action\n)\n\n# Ask the agent for the solution of a mathematical equation.\nagent_executor.run(\"What is the square root of 250? Round the answer down to 4 decimals.\")","outputsMetadata":{"0":{"height":416,"type":"stream"}}},"id":"9016d465-16b8-48d8-af78-3384a113eaa3","cell_type":"code","execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":"\n\n\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"},{"output_type":"stream","name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning:\n\nThe method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n\n"},{"output_type":"stream","name":"stdout","text":"\u001b[32;1m\u001b[1;3m I can use the math module to calculate the square root.\nAction: Python_REPL\nAction Input: import math\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m Now that the math module is imported, I can use the sqrt function.\nAction: Python_REPL\nAction Input: math.sqrt(250)\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m The result is a float, so I can use the round function to round it down to 4 decimals.\nAction: Python_REPL\nAction Input: round(math.sqrt(250), 4)\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m I now know the final answer.\nFinal Answer: 15.8114\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\n"},{"output_type":"execute_result","data":{"text/plain":"'15.8114'"},"metadata":{},"execution_count":14}]},{"source":"Ask the agent to extract the company name and sentiment from the headlines and save its output in a `.csv` file called `financial_analysis.csv`.\n- Invoke the agent on the following prompt:\n    \n    ``` \n    f\"\"\"For every of the following headlines, extract the company name and whether the financial sentiment is positive, neutral or negative. \n    Load this data into a pandas dataframe. \n    The dataframe will have three columns: the name of the company, whether the financial sentiment is positive or negative and the headline itself. \n    The dataframe can then be saved in the current working directory under the name financial_analysis.csv.\n    If a csv file already exists with the same name, it should be overwritten.\n\n    The headlines are the following:\n    {headlines}\"\"\"\n    ```","metadata":{},"id":"044d23e5-930f-4a11-b3ff-fb42e61222cd","cell_type":"markdown"},{"source":"# Invoke the agent\nagent_executor.invoke(f\"\"\"For every of the following headlines, extract the company name and whether the financial sentiment is positive, neutral or negative. \nLoad this data into a pandas dataframe. \nThe dataframe will have three columns: the name of the company, whether the financial sentiment is positive or negative and the headline itself. \nThe dataframe can then be saved in the current working directory under the name financial_analysis.csv.\nIf a csv file already exists with the same name, it should be overwritten.\n\nThe headlines are the following:\n{headlines}\"\"\")","metadata":{"executionCancelledAt":null,"executionTime":13848,"lastExecutedAt":1749074369749,"lastExecutedByKernel":"6915a89c-0b39-433b-a056-35cfb360a427","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Invoke the agent\nagent_executor.invoke(f\"\"\"For every of the following headlines, extract the company name and whether the financial sentiment is positive, neutral or negative. \nLoad this data into a pandas dataframe. \nThe dataframe will have three columns: the name of the company, whether the financial sentiment is positive or negative and the headline itself. \nThe dataframe can then be saved in the current working directory under the name financial_analysis.csv.\nIf a csv file already exists with the same name, it should be overwritten.\n\nThe headlines are the following:\n{headlines}\"\"\")","outputsMetadata":{"0":{"height":616,"type":"stream"}}},"id":"d6b142a8-d387-4738-90de-c4d7f7d74fc3","cell_type":"code","execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":"\n\n\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n\u001b[32;1m\u001b[1;3m I need to import the necessary libraries and modules to work with pandas and csv files.\nAction: Python_REPL\nAction Input: import pandas as pd\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m I need to create a list of the headlines.\nAction: Python_REPL\nAction Input: headlines = [\"Finnish Aktia Group 's operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .\", 'Finnish measuring equipment maker Vaisala Oyj HEL : VAIAS said today that its net loss widened to EUR4 .8 m in the first half of 2010 from EUR2 .3 m in the corresponding period a year earlier .', 'Finnish pharmaceuticals company Orion reports profit before taxes of EUR 70.0 mn in the third quarter of 2010 , up from EUR 54.9 mn in the corresponding period in 2009 .', 'Tiimari , the Finnish retailer , reported to have geenrated quarterly revenues totalling EUR 1.3 mn in the 4th quarter 2009 , up from EUR 0.3 mn loss in 2008 .', \"Finnish Metso Paper has been awarded a contract for the rebuild of Sabah Forest Industries ' ( SFI ) pulp mill in Sabah , Malaysia .\", 'Finnish Outokumpu Technology has been awarded several new grinding technology contracts .']\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m I need to create a pandas dataframe with three columns: company name, financial sentiment, and headline.\nAction: Python_REPL\nAction Input: df = pd.DataFrame(columns=['Company Name', 'Financial Sentiment', 'Headline'])\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m I need to extract the company name and financial sentiment from each headline and add it to the dataframe.\nAction: Python_REPL\nAction Input: for headline in headlines:\n    if 'Finnish' in headline:\n        company_name = 'Finnish'\n    else:\n        company_name = 'Unknown'\n    if 'profit' in headline or 'revenues' in headline:\n        financial_sentiment = 'Positive'\n    elif 'loss' in headline:\n        financial_sentiment = 'Negative'\n    else:\n        financial_sentiment = 'Neutral'\n    df = df.append({'Company Name': company_name, 'Financial Sentiment': financial_sentiment, 'Headline': headline}, ignore_index=True)\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3mAttributeError(\"'DataFrame' object has no attribute 'append'\")\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m I need to use the pandas .loc method to add rows to the dataframe.\nAction: Python_REPL\nAction Input: for headline in headlines:\n    if 'Finnish' in headline:\n        company_name = 'Finnish'\n    else:\n        company_name = 'Unknown'\n    if 'profit' in headline or 'revenues' in headline:\n        financial_sentiment = 'Positive'\n    elif 'loss' in headline:\n        financial_sentiment = 'Negative'\n    else:\n        financial_sentiment = 'Neutral'\n    df.loc[len(df)] = [company_name, financial_sentiment, headline]\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m I need to save the dataframe as a csv file in the current working directory.\nAction: Python_REPL\nAction Input: df.to_csv('financial_analysis.csv', index=False)\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m I now know the final answer.\nFinal Answer: The dataframe with the extracted company names, financial sentiment, and headlines has been saved as financial_analysis.csv in the current working directory.\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\n"},{"output_type":"execute_result","data":{"text/plain":"{'input': 'For every of the following headlines, extract the company name and whether the financial sentiment is positive, neutral or negative. \\nLoad this data into a pandas dataframe. \\nThe dataframe will have three columns: the name of the company, whether the financial sentiment is positive or negative and the headline itself. \\nThe dataframe can then be saved in the current working directory under the name financial_analysis.csv.\\nIf a csv file already exists with the same name, it should be overwritten.\\n\\nThe headlines are the following:\\n[\"Finnish Aktia Group \\'s operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .\", \\'Finnish measuring equipment maker Vaisala Oyj HEL : VAIAS said today that its net loss widened to EUR4 .8 m in the first half of 2010 from EUR2 .3 m in the corresponding period a year earlier .\\', \\'Finnish pharmaceuticals company Orion reports profit before taxes of EUR 70.0 mn in the third quarter of 2010 , up from EUR 54.9 mn in the corresponding period in 2009 .\\', \\'Tiimari , the Finnish retailer , reported to have geenrated quarterly revenues totalling EUR 1.3 mn in the 4th quarter 2009 , up from EUR 0.3 mn loss in 2008 .\\', \"Finnish Metso Paper has been awarded a contract for the rebuild of Sabah Forest Industries \\' ( SFI ) pulp mill in Sabah , Malaysia .\", \\'Finnish Outokumpu Technology has been awarded several new grinding technology contracts .\\']',\n 'output': 'The dataframe with the extracted company names, financial sentiment, and headlines has been saved as financial_analysis.csv in the current working directory.'}"},"metadata":{},"execution_count":15}]},{"source":"Observe the output above. Do you see anything that could be improved? We will come back to this later in this notebook.\n\nFor now, let's quickly load our `.csv` file in a dataframe to analyze.","metadata":{},"id":"f4865a0e-2caf-4242-802f-1553ba1d3b5d","cell_type":"markdown"},{"source":"\nLoad the data in a dataframe for evaluation.\n- Import `pandas` under its usual alias: `pd`.\n- Load the `financial_analysis.csv` file into a dataframe. Assign to `df`.\n- Print the dataframe. As our dataframe only contains six rows, we can just print the entire dataframe.","metadata":{},"id":"86270b08-e124-43bb-8834-210bdb6c0a43","cell_type":"markdown"},{"source":"# Make the necessary import.\nimport pandas as pd\n\n# Load the CSV file into a dataframe.\ndf = pd.read_csv(\"financial_analysis.csv\")\n\n# Print the dataframe.\ndf","metadata":{"executionCancelledAt":null,"executionTime":55,"lastExecutedAt":1749074369804,"lastExecutedByKernel":"6915a89c-0b39-433b-a056-35cfb360a427","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Make the necessary import.\nimport pandas as pd\n\n# Load the CSV file into a dataframe.\ndf = pd.read_csv(\"financial_analysis.csv\")\n\n# Print the dataframe.\ndf","outputsMetadata":{"0":{"height":50,"type":"dataFrame","tableState":{"customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"f3b752a8-642c-4da5-85cc-0a713db1ad8f","nodeType":"const"}}}}},"id":"e1c01e13-0d39-407d-80f6-f0ebe5f76827","cell_type":"code","execution_count":16,"outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"Company Name","type":"string"},{"name":"Financial Sentiment","type":"string"},{"name":"Headline","type":"string"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":[0,1,2,3,4,5],"Company Name":["Finnish","Finnish","Finnish","Finnish","Finnish","Finnish"],"Financial Sentiment":["Positive","Negative","Positive","Positive","Neutral","Neutral"],"Headline":["Finnish Aktia Group 's operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .","Finnish measuring equipment maker Vaisala Oyj HEL : VAIAS said today that its net loss widened to EUR4 .8 m in the first half of 2010 from EUR2 .3 m in the corresponding period a year earlier .","Finnish pharmaceuticals company Orion reports profit before taxes of EUR 70.0 mn in the third quarter of 2010 , up from EUR 54.9 mn in the corresponding period in 2009 .","Tiimari , the Finnish retailer , reported to have geenrated quarterly revenues totalling EUR 1.3 mn in the 4th quarter 2009 , up from EUR 0.3 mn loss in 2008 .","Finnish Metso Paper has been awarded a contract for the rebuild of Sabah Forest Industries ' ( SFI ) pulp mill in Sabah , Malaysia .","Finnish Outokumpu Technology has been awarded several new grinding technology contracts ."]}},"total_rows":6,"truncation_type":null},"text/plain":"  Company Name  ...                                           Headline\n0      Finnish  ...  Finnish Aktia Group 's operating profit rose t...\n1      Finnish  ...  Finnish measuring equipment maker Vaisala Oyj ...\n2      Finnish  ...  Finnish pharmaceuticals company Orion reports ...\n3      Finnish  ...  Tiimari , the Finnish retailer , reported to h...\n4      Finnish  ...  Finnish Metso Paper has been awarded a contrac...\n5      Finnish  ...  Finnish Outokumpu Technology has been awarded ...\n\n[6 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Company Name</th>\n      <th>Financial Sentiment</th>\n      <th>Headline</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Finnish</td>\n      <td>Positive</td>\n      <td>Finnish Aktia Group 's operating profit rose t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Finnish</td>\n      <td>Negative</td>\n      <td>Finnish measuring equipment maker Vaisala Oyj ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Finnish</td>\n      <td>Positive</td>\n      <td>Finnish pharmaceuticals company Orion reports ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Finnish</td>\n      <td>Positive</td>\n      <td>Tiimari , the Finnish retailer , reported to h...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Finnish</td>\n      <td>Neutral</td>\n      <td>Finnish Metso Paper has been awarded a contrac...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Finnish</td>\n      <td>Neutral</td>\n      <td>Finnish Outokumpu Technology has been awarded ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{"application/com.datacamp.data-table.v2+json":{"status":"success"}},"execution_count":16}]},{"source":"## Analysis of Output and Room for Improvement\n\nWhen analyzing the output above (looking at the company names and sentiment), you will probably notice some room for improvement. \n\n### Issues Identified\n\n1. **Extraction Method**: \n   - Company names and sentiment may not be extracted in a very powerful way. The reason for this is that without further instructions, the GPT-model will use the PythonREPLTool (Python code) to complete its task. \n   - Looking back at the output from our last call to the Python agent, we may find that it created rule sets on how to extract the company name or determine the sentiment. These hard-coded rules negate the power of large language models!\n\n2. **Sentiment vs. Financial Sentiment**:\n   - Another problem that might arise is that the *sentiment* of a sentence can differ from *financial sentiment*. \n   - For example, an aggressive headline complaining about a large corporation making too much profit might result in negative sentiment, while from a financial analysis point of view the sentiment is positive. \n\n### Solution: Few-Shot Learning\n\nTo steer the GPT-model to our desired outcome, we will now introduce few-shot learning.\n\n#### Example\n\n- *Company X was awarded a new contract* might be categorized as a neutral sentence. The sentence itself is simply an objective statement or observation. Nothing is mentioned about whether we like or dislike that particular company because of this. \n- From a financial perspective however, this is considered as something positive. \n\nTo steer the GPT-model to our desired outcome, we will now introduce few-shot learning.\n```","metadata":{},"id":"d37d368b-b177-41f9-abe8-dacf99486401","cell_type":"markdown"},{"source":"## Adding Few Shot Learning","metadata":{},"id":"31bb73ca-089b-4bdf-ba9f-e2efbe3174f0","cell_type":"markdown"},{"source":"Few shot learning basically comes down to adding some examples into our prompt, in this case, what we consider to be positive or negative headlines. A shot refers to an example given to the model in the input prompt (or sometimes the system message).\n\nWe distinguish three categories of contextual learning:\n- Few shot leaning (multiple examples)\n- Single shot learning (one example)\n- Zero shot leaning (no examples)\n\nFew shot learning might take more effort in terms of prompt building, but it will generally yield better results, as the model has a better understanding of our desired outcome.\n\nLet's look at an example of financial sentiment analysis without few shot learning first.","metadata":{},"id":"cbe98ba4-9d30-40e7-8a80-d8b780a48105","cell_type":"markdown"},{"source":"Create a prompt template with output parsing to determine the financial sentiment of all headlines.\n- Create a new `PromptTemplate` called `sentiment_template`. Remember the three arguments `template`, `input_variables` and `partial_variables`. Assign to `sentiment_template`.\n    - We can reuse the `format_instructions` variable that we have loaded into memory before.\n    - As a template, use: \n```\n\"Get the financial sentiment of each of the following headlines. The output is strictly limited to any of the following options: ['Positive', 'Negative', 'Neutral']: {headlines}.\\n{format_instructions}\"\n```\n\n\n- Format the template on all headlines. Assign to `formatted_sentiment_template`.\n- Run the formatted template by invoking our `model` and assign the result to our temporary variable `_output`.\n- Parse the output using the output parser. Assign the result to `sentiments`.\n- Print the sentiments.","metadata":{},"id":"59658d1d-3b7c-4e7c-8521-c295982c3de7","cell_type":"markdown"},{"source":"# Create a new prompt template with output parsing.\nsentiment_template = PromptTemplate(\n    template = \"Get the financial sentiment of each of the following headlines. The output is strictly limited to any of the following options: ['Positive', 'Negative', 'Neutral']: {headlines}.\\n{format_instructions}\",\n    input_variables = [\"headlines\"],\n    partial_variables = {\"format_instructions\": format_instructions}\n)\n\n# Format the prompt template.\nformatted_sentiment_template = sentiment_template.format(headlines=headlines)\n\n# Invoke the model on the formatted prompt template.\n_output = model.invoke(formatted_sentiment_template)\n\n# Parse the output.\nsentiments  = output_parser.parse(_output)\n\n# Print the list of sentiments.\nsentiments","metadata":{"executionCancelledAt":null,"executionTime":819,"lastExecutedAt":1749074370623,"lastExecutedByKernel":"6915a89c-0b39-433b-a056-35cfb360a427","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Create a new prompt template with output parsing.\nsentiment_template = PromptTemplate(\n    template = \"Get the financial sentiment of each of the following headlines. The output is strictly limited to any of the following options: ['Positive', 'Negative', 'Neutral']: {headlines}.\\n{format_instructions}\",\n    input_variables = [\"headlines\"],\n    partial_variables = {\"format_instructions\": format_instructions}\n)\n\n# Format the prompt template.\nformatted_sentiment_template = sentiment_template.format(headlines=headlines)\n\n# Invoke the model on the formatted prompt template.\n_output = model.invoke(formatted_sentiment_template)\n\n# Parse the output.\nsentiments  = output_parser.parse(_output)\n\n# Print the list of sentiments.\nsentiments"},"id":"30dc1956-488a-4c93-a887-a5ea803f30a4","cell_type":"code","execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":"['Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive']"},"metadata":{},"execution_count":17}]},{"source":"It is hard to evaluate the sentiments without seeing the associated headline. To make our lives easier, let's write a quick function to easily visualize and interpret the result.","metadata":{},"id":"843f4c4d-8185-4ebe-991b-1d179cc5e15a","cell_type":"markdown"},{"source":"\nVisualize and interpret the results of the sentiment analysis.\n- Write a function called `visualize_sentiments` to visualize both the sentiment and associated headline, for all headlines. \n    - The input for this function should be two lists: one containing all headlines and one containing all sentiments.\n    - As a best practice, start with using an `assert` that ensures that both lists are of equal length.\n    - There are many ways to create this: simply printing with f-strings, making a dictionary or Dataframe, get creative!\n- Call the `visualize_sentiments` function using `headlines` and `sentiments` as input.","metadata":{},"id":"da3d6834-6c1e-4542-80f3-dc1b385f6477","cell_type":"markdown"},{"source":"# Define a new function with two inputs,\ndef visualize_sentiments(headlines, sentiments):\n    # Assert that both inputs are of equal length\n    assert len(headlines) == len(sentiments)\n\n    # Visualize the sentiments and their respective headlines\n    for i, _ in enumerate(headlines):\n        print(f\"{sentiments[i].upper()}: {headlines[i]}\")\n\n# Call the function\nvisualize_sentiments(headlines, sentiments)","metadata":{"executionCancelledAt":null,"executionTime":49,"lastExecutedAt":1749074370672,"lastExecutedByKernel":"6915a89c-0b39-433b-a056-35cfb360a427","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define a new function with two inputs,\ndef visualize_sentiments(headlines, sentiments):\n    # Assert that both inputs are of equal length\n    assert len(headlines) == len(sentiments)\n\n    # Visualize the sentiments and their respective headlines\n    for i, _ in enumerate(headlines):\n        print(f\"{sentiments[i].upper()}: {headlines[i]}\")\n\n# Call the function\nvisualize_sentiments(headlines, sentiments)"},"id":"4e7ca1a7-4249-4826-ac57-5093ee3de9d1","cell_type":"code","execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":"POSITIVE: Finnish Aktia Group 's operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .\nNEGATIVE: Finnish measuring equipment maker Vaisala Oyj HEL : VAIAS said today that its net loss widened to EUR4 .8 m in the first half of 2010 from EUR2 .3 m in the corresponding period a year earlier .\nPOSITIVE: Finnish pharmaceuticals company Orion reports profit before taxes of EUR 70.0 mn in the third quarter of 2010 , up from EUR 54.9 mn in the corresponding period in 2009 .\nPOSITIVE: Tiimari , the Finnish retailer , reported to have geenrated quarterly revenues totalling EUR 1.3 mn in the 4th quarter 2009 , up from EUR 0.3 mn loss in 2008 .\nPOSITIVE: Finnish Metso Paper has been awarded a contract for the rebuild of Sabah Forest Industries ' ( SFI ) pulp mill in Sabah , Malaysia .\nPOSITIVE: Finnish Outokumpu Technology has been awarded several new grinding technology contracts .\n"}]},{"source":"Now we might see that the financial sentiment is not always correctly assigned, such as a contract being awarded not being recognized as a financially positive headline.\nTo improve the performance, we will add some examples. Few shot learning can be done by either giving some observations (headlines in this case) accompanied by their ground truth (label) *or* by giving an abstract description of what is seen as positive, negative or neutral.\n\nIn this case, we will opt for the later. Here is a prompt you can use for few shot learning:\n\n```\n\"\"\"\nIf a company is doing financially better than before, the sentiment is positive. For example, when profits or revenue have increased since the last quarter or year, exceeding expectations, a contract is awarded or an acquisition is announced.\nIf the company's profits are decreasing, losses are mounting up or overall performance is not meeting expectations, the sentiment is negative.\nIf nothing positive or negative is mentioned from a financial perspective, the sentiment is neutral.\n\"\"\"\n```","metadata":{},"id":"3bc7af8c-461c-42d2-ae37-2da14438c5c6","cell_type":"markdown"},{"source":"\nCreate and run a prompt template using few shot learning.\n- Store the prompt above in a variable called `sentiment_examples`.\n- Create a `PromptTemplate` called `sentiment_template` like we did two cells above.\n    - In our template, we will add a new input variable called `few_shot_examples`. This can be placed in between the two sentences.\n    - Don't forget to add our new input variables to the list of `input_variables`.\n    - Reuse the same `format_instructions` as before.\n- Format the `sentiment_template`. Remember that you will need to pass both `headlines` and `sentiment_examples`.\n- Run the formatted template by invoking our `model` and assign the result to our temporary variable `_output`.\n- Parse the output using the output parser. Assign the result to `sentiments`.\n- Visualize and interpret the results using your newly created `visualize_sentiments` function.","metadata":{},"id":"3142596a-b723-4d4f-9d2d-2066531aeea6","cell_type":"markdown"},{"source":"# Store the few shot examples in a variable.\nsentiment_examples = \"\"\"\n    If a company is doing financially better than before, the sentiment is positive. For example, when profits or revenue have increased since the last quarter or year, exceeding expectations, a contract is awarded or an acquisition is announced.\n    If the company's profits are decreasing, losses are mounting up or overall performance is not meeting expectations, the sentiment is negative.\n    If nothing positive or negative is mentioned from a financial perspective, the sentiment is neutral.\n\"\"\"\n\n# Instantiate a new prompt template with the format instructions.\nsentiment_template = PromptTemplate(\n    template=\"Get the financial sentiment of each of the following headlines. {few_shot_examples} The output is strictly limited to any of the following options: ['Positive', 'Negative', 'Neutral']: {headlines}.\\n{format_instructions}\",\n    input_variables=[\"headlines\", \"few_shot_examples\"],\n    partial_variables={\"format_instructions\": format_instructions}\n)\n\n# Format the template.\nformatted_sentiment_template = sentiment_template.format(\n\theadlines=headlines, \n\tfew_shot_examples=sentiment_examples\n)\n\n# Invoke the model on the formatted template.\n_output = model.invoke(formatted_sentiment_template)\n\n# Parse the model output.\nsentiments = output_parser.parse(_output)\n\n# Visualize the result.\nvisualize_sentiments(headlines, sentiments)","metadata":{"executionCancelledAt":null,"executionTime":588,"lastExecutedAt":1749074371260,"lastExecutedByKernel":"6915a89c-0b39-433b-a056-35cfb360a427","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Store the few shot examples in a variable.\nsentiment_examples = \"\"\"\n    If a company is doing financially better than before, the sentiment is positive. For example, when profits or revenue have increased since the last quarter or year, exceeding expectations, a contract is awarded or an acquisition is announced.\n    If the company's profits are decreasing, losses are mounting up or overall performance is not meeting expectations, the sentiment is negative.\n    If nothing positive or negative is mentioned from a financial perspective, the sentiment is neutral.\n\"\"\"\n\n# Instantiate a new prompt template with the format instructions.\nsentiment_template = PromptTemplate(\n    template=\"Get the financial sentiment of each of the following headlines. {few_shot_examples} The output is strictly limited to any of the following options: ['Positive', 'Negative', 'Neutral']: {headlines}.\\n{format_instructions}\",\n    input_variables=[\"headlines\", \"few_shot_examples\"],\n    partial_variables={\"format_instructions\": format_instructions}\n)\n\n# Format the template.\nformatted_sentiment_template = sentiment_template.format(\n\theadlines=headlines, \n\tfew_shot_examples=sentiment_examples\n)\n\n# Invoke the model on the formatted template.\n_output = model.invoke(formatted_sentiment_template)\n\n# Parse the model output.\nsentiments = output_parser.parse(_output)\n\n# Visualize the result.\nvisualize_sentiments(headlines, sentiments)"},"id":"78e963c2-d4a5-409b-b4b7-7a1d30a13346","cell_type":"code","execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":"POSITIVE: Finnish Aktia Group 's operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .\nNEGATIVE: Finnish measuring equipment maker Vaisala Oyj HEL : VAIAS said today that its net loss widened to EUR4 .8 m in the first half of 2010 from EUR2 .3 m in the corresponding period a year earlier .\nPOSITIVE: Finnish pharmaceuticals company Orion reports profit before taxes of EUR 70.0 mn in the third quarter of 2010 , up from EUR 54.9 mn in the corresponding period in 2009 .\nPOSITIVE: Tiimari , the Finnish retailer , reported to have geenrated quarterly revenues totalling EUR 1.3 mn in the 4th quarter 2009 , up from EUR 0.3 mn loss in 2008 .\nPOSITIVE: Finnish Metso Paper has been awarded a contract for the rebuild of Sabah Forest Industries ' ( SFI ) pulp mill in Sabah , Malaysia .\nPOSITIVE: Finnish Outokumpu Technology has been awarded several new grinding technology contracts .\n"}]},{"source":"## Combining Tools and Output Parsing","metadata":{},"id":"300e7f24-e934-4c49-a710-c67cb3413693","cell_type":"markdown"},{"source":"As you may have noticed in Task 5, using tools is not a guaranteed success. We can improve the performance by clearly determining which tasks can be completed by the Python tool and which we use the GPT-model itself for.\nTo maximize the powerful capabilities of the GPT-model, we prefer its use over hard-coded rule sets when it comes to company name extraction or financial sentiment analysis.\nHowever, other (cumbersome) tasks that do not require the ability to handle ambiguity, are often best left to the Python tool.\n\nLet's ask the model to use the existing lists that we got from our templates (`company_names` and `sentiments`), but use the Python tool to neatly place them in a Pandas dataframe and write them locally to a `.csv` file.\n\nUse the following prompt:\n\n```\nf\"\"\"Create a dataframe with two columns: company_name, sentiment and headline.\n                   To fill the dataframe, use the following lists respectively: {str(company_names)}, {str(sentiments)} and {str(headlines)}. \n                   The dataframe can then be saved in the current working directory under the name financial_analysis_with_parsing.csv.\n                   If a csv file already exists with the same name, it should be overwritten.\n                   \"\"\"\n```\n\nIn the prompt above, we pass along lists that were generated by the GPT-model before (when it did not have access to the Python tool). Now we only want to give instructions on tasks that should be carried out using Python code, such as the creation of the dataframe, saving (and overwriting) it, ...\n\nKeep in mind that we can use this same way of working for much more complex tasks, that might encompass extensive coding requirements.","metadata":{},"id":"4e447e81-3b31-4e74-a567-53623cc863ce","cell_type":"markdown"},{"source":"- Invoke the `agent_executor` on the prompt above.","metadata":{},"id":"d690b3d5-2602-4c3b-990f-85990d4e301d","cell_type":"markdown"},{"source":"# Invoke the agent to create a file with the headlines, company names and sentiments.\nagent_executor.invoke(f\"\"\"Create a dataframe with two columns: company_name, sentiment and headline.\n                   To fill the dataframe, use the following lists respectively: {str(company_names)}, {str(sentiments)} and {str(headlines)}. \n                   The dataframe can then be saved in the current working directory under the name financial_analysis_with_parsing.csv.\n                   If a csv file already exists with the same name, it should be overwritten.\n                   \"\"\")","metadata":{"executionCancelledAt":null,"executionTime":6451,"lastExecutedAt":1749074377711,"lastExecutedByKernel":"6915a89c-0b39-433b-a056-35cfb360a427","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Invoke the agent to create a file with the headlines, company names and sentiments.\nagent_executor.invoke(f\"\"\"Create a dataframe with two columns: company_name, sentiment and headline.\n                   To fill the dataframe, use the following lists respectively: {str(company_names)}, {str(sentiments)} and {str(headlines)}. \n                   The dataframe can then be saved in the current working directory under the name financial_analysis_with_parsing.csv.\n                   If a csv file already exists with the same name, it should be overwritten.\n                   \"\"\")","outputsMetadata":{"0":{"height":521,"type":"stream"}}},"id":"188e0ab4-1515-49a2-a8db-09582ec5be21","cell_type":"code","execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":"\n\n\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n\u001b[32;1m\u001b[1;3m I need to import pandas to create a dataframe. I also need to create the lists for the columns and the data.\nAction: Python_REPL\nAction Input: import pandas as pd\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m Now that I have imported pandas, I can create the dataframe using the lists.\nAction: Python_REPL\nAction Input: df = pd.DataFrame({'company_name': ['Aktia Group', 'Vaisala Oyj', 'Orion', 'Tiimari', 'Metso Paper', 'Outokumpu Technology'], 'sentiment': ['Positive', 'Negative', 'Positive', 'Positive', 'Positive', 'Positive'], 'headline': [\"Finnish Aktia Group 's operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .\", 'Finnish measuring equipment maker Vaisala Oyj HEL : VAIAS said today that its net loss widened to EUR4 .8 m in the first half of 2010 from EUR2 .3 m in the corresponding period a year earlier .', 'Finnish pharmaceuticals company Orion reports profit before taxes of EUR 70.0 mn in the third quarter of 2010 , up from EUR 54.9 mn in the corresponding period in 2009 .', 'Tiimari , the Finnish retailer , reported to have geenrated quarterly revenues totalling EUR 1.3 mn in the 4th quarter 2009 , up from EUR 0.3 mn loss in 2008 .', \"Finnish Metso Paper has been awarded a contract for the rebuild of Sabah Forest Industries ' ( SFI ) pulp mill in Sabah , Malaysia .\", 'Finnish Outokumpu Technology has been awarded several new grinding technology contracts .']})\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m Now that I have created the dataframe, I need to save it in the current working directory.\nAction: Python_REPL\nAction Input: df.to_csv('financial_analysis_with_parsing.csv', index=False)\u001b[0m\nObservation: \u001b[36;1m\u001b[1;3m\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m I now know the final answer.\nFinal Answer: The dataframe has been saved in the current working directory under the name financial_analysis_with_parsing.csv.\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\n"},{"output_type":"execute_result","data":{"text/plain":"{'input': 'Create a dataframe with two columns: company_name, sentiment and headline.\\n                   To fill the dataframe, use the following lists respectively: [\\'Aktia Group\\', \\'Vaisala Oyj\\', \\'Orion\\', \\'Tiimari\\', \\'Metso Paper\\', \\'Outokumpu Technology\\'], [\\'Positive\\', \\'Negative\\', \\'Positive\\', \\'Positive\\', \\'Positive\\', \\'Positive\\'] and [\"Finnish Aktia Group \\'s operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .\", \\'Finnish measuring equipment maker Vaisala Oyj HEL : VAIAS said today that its net loss widened to EUR4 .8 m in the first half of 2010 from EUR2 .3 m in the corresponding period a year earlier .\\', \\'Finnish pharmaceuticals company Orion reports profit before taxes of EUR 70.0 mn in the third quarter of 2010 , up from EUR 54.9 mn in the corresponding period in 2009 .\\', \\'Tiimari , the Finnish retailer , reported to have geenrated quarterly revenues totalling EUR 1.3 mn in the 4th quarter 2009 , up from EUR 0.3 mn loss in 2008 .\\', \"Finnish Metso Paper has been awarded a contract for the rebuild of Sabah Forest Industries \\' ( SFI ) pulp mill in Sabah , Malaysia .\", \\'Finnish Outokumpu Technology has been awarded several new grinding technology contracts .\\']. \\n                   The dataframe can then be saved in the current working directory under the name financial_analysis_with_parsing.csv.\\n                   If a csv file already exists with the same name, it should be overwritten.\\n                   ',\n 'output': 'The dataframe has been saved in the current working directory under the name financial_analysis_with_parsing.csv.'}"},"metadata":{},"execution_count":20}]},{"source":"If we look at our working directory, we will see a new file pop up, called `financial_analysis_with_parsing.csv`.\n\nLet's analyze it and compare against the output from Task 5.","metadata":{},"id":"477b7d8a-2e4e-4f74-8dc1-b538fcd09f23","cell_type":"markdown"},{"source":"Load and display the new file.\n- Load `financial_analysis_with_parsing.csv` into a dataframe called `df`.\n- Print the dataframe.","metadata":{},"id":"9ed9c0b7-f961-493e-8a38-7143050448f8","cell_type":"markdown"},{"source":"# Load the CSV file into a dataframe.\ndf = pd.read_csv(\"financial_analysis_with_parsing.csv\")\n\n# Print the dataframe.\ndf","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1749074377763,"lastExecutedByKernel":"6915a89c-0b39-433b-a056-35cfb360a427","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Load the CSV file into a dataframe.\ndf = pd.read_csv(\"financial_analysis_with_parsing.csv\")\n\n# Print the dataframe.\ndf","outputsMetadata":{"0":{"height":50,"type":"dataFrame","tableState":{"customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"f3b752a8-642c-4da5-85cc-0a713db1ad8f","nodeType":"const"}}}}},"id":"142e344b-16c6-46fa-996f-3c1da9b52956","cell_type":"code","execution_count":21,"outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"company_name","type":"string"},{"name":"sentiment","type":"string"},{"name":"headline","type":"string"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":[0,1,2,3,4,5],"company_name":["Aktia Group","Vaisala Oyj","Orion","Tiimari","Metso Paper","Outokumpu Technology"],"sentiment":["Positive","Negative","Positive","Positive","Positive","Positive"],"headline":["Finnish Aktia Group 's operating profit rose to EUR 17.5 mn in the first quarter of 2010 from EUR 8.2 mn in the first quarter of 2009 .","Finnish measuring equipment maker Vaisala Oyj HEL : VAIAS said today that its net loss widened to EUR4 .8 m in the first half of 2010 from EUR2 .3 m in the corresponding period a year earlier .","Finnish pharmaceuticals company Orion reports profit before taxes of EUR 70.0 mn in the third quarter of 2010 , up from EUR 54.9 mn in the corresponding period in 2009 .","Tiimari , the Finnish retailer , reported to have geenrated quarterly revenues totalling EUR 1.3 mn in the 4th quarter 2009 , up from EUR 0.3 mn loss in 2008 .","Finnish Metso Paper has been awarded a contract for the rebuild of Sabah Forest Industries ' ( SFI ) pulp mill in Sabah , Malaysia .","Finnish Outokumpu Technology has been awarded several new grinding technology contracts ."]}},"total_rows":6,"truncation_type":null},"text/plain":"           company_name  ...                                           headline\n0           Aktia Group  ...  Finnish Aktia Group 's operating profit rose t...\n1           Vaisala Oyj  ...  Finnish measuring equipment maker Vaisala Oyj ...\n2                 Orion  ...  Finnish pharmaceuticals company Orion reports ...\n3               Tiimari  ...  Tiimari , the Finnish retailer , reported to h...\n4           Metso Paper  ...  Finnish Metso Paper has been awarded a contrac...\n5  Outokumpu Technology  ...  Finnish Outokumpu Technology has been awarded ...\n\n[6 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>company_name</th>\n      <th>sentiment</th>\n      <th>headline</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Aktia Group</td>\n      <td>Positive</td>\n      <td>Finnish Aktia Group 's operating profit rose t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Vaisala Oyj</td>\n      <td>Negative</td>\n      <td>Finnish measuring equipment maker Vaisala Oyj ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Orion</td>\n      <td>Positive</td>\n      <td>Finnish pharmaceuticals company Orion reports ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Tiimari</td>\n      <td>Positive</td>\n      <td>Tiimari , the Finnish retailer , reported to h...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Metso Paper</td>\n      <td>Positive</td>\n      <td>Finnish Metso Paper has been awarded a contrac...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Outokumpu Technology</td>\n      <td>Positive</td>\n      <td>Finnish Outokumpu Technology has been awarded ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{"application/com.datacamp.data-table.v2+json":{"status":"success"}},"execution_count":21}]},{"source":"## Using the OpenAI Moderation API","metadata":{},"id":"50ca52ca-41f3-4aea-bd0a-4862a9465a7a","cell_type":"markdown"},{"source":"The OpenAI API platform also sports a Moderation API, in addition to their model and embeddings APIs. The Moderation API can check whether the prompt contains explicit content and can flag various categories like hate, violence, sexually explicit content, and more. When we are building an application targeting large user bases, it becomes crucial to leverage the Moderation API and filter our input prompts to avoid the complications associated with unethical LLM usage.\n\nTo test the Moderation API, we have a small sample of five comments picked from the `r/WallStreetBets` subreddit, stored in the `reddit_comments.txt` file.\n\nLet's start by reading the text file and displaying its contents to understand what kind of comments we are dealing with. This will help us see how the Moderation API can be applied to real-world data.\n\nHere are the steps we will follow:\n1. Read the `reddit_comments.txt` file.\n2. Display the contents of the file.","metadata":{},"id":"27cd50c5-43a2-4082-8dde-d92c183d38cd","cell_type":"markdown"},{"source":"Read the text file and store its lines in a variable called `comments`.\n- Open `reddit_comments.txt` as read.\n- Use the `.readlines()` method to store its contents in a list called `comments`.\n- Optionally print the comments.","metadata":{},"id":"4e66ebca-010f-4189-b2fd-3a33ec0b378d","cell_type":"markdown"},{"source":"# Load the lines of the text file.\nwith open('reddit_comments.txt', 'r') as data:\n    comments = data.readlines()\n\n# Optionally print the comments.\ncomments","metadata":{"executionCancelledAt":null,"executionTime":53,"lastExecutedAt":1749074377816,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Load the lines of the text file.\nwith open('reddit_comments.txt', 'r') as data:\n    comments = data.readlines()\n\n# Optionally print the comments.\ncomments","lastExecutedByKernel":"6915a89c-0b39-433b-a056-35cfb360a427"},"id":"a5a029ff-5387-49f7-8a77-e3cdd40e7282","cell_type":"code","execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":"[\"It's the poors fault for thinking they had a chance in a negative sum gambling casino run by people richer than you who hired Asian quants that are smarter than you.\\n\",\n \"Canada is basically a global real estate investment scheme. It's not even a country, it's a showroom.\\n\",\n 'Lol China not going to make a dent in the global scale. Wake me up when America’s housing market is about to implode that’s when I’m pulling out all my investments. Because the world is going to burn.\\n',\n 'I would normally have the knee-jerk reaction to seethe at this post but I remind myself that if I had a lot of money I would probably be the snobbiest and stingiest rich person ever. I wouldn’t even help anyone even if they begged me to financially free them from their Wendy’s dumpster obligations\\n',\n \"I know China will be fine because Peter Zeihan keeps saying China is imploding. If you want to know what the US State Department desperately wants you to believe, just keep up to date with whatever Peter Zeihan is saying. The dude somehow made a career about being wrong about everything all the time and always blindsided by new developments. 3 months ago he's doing vblogs about how China is completely cut off from semiconductors and the immensely complicated tech necessary to catch up - and then last week it's revealed China has beaten USA to producing 7nm chips domestically. Literally just 3 months ago Zeihan and everyone educated by Western news sources thought China would be stuck at 28nm for years to come. If the rumours circulating of China developing SSMB EUV are true then it's truly game over, China's won\"]"},"metadata":{},"execution_count":22}]},{"source":"Analyze a comment using the Moderation API.\n- Pick a comment from the dataset and store this in a variable called `comment`.\n- Use the `openai` package to define an OpenAI model. Assign to `client`.\n- Use the API by calling the previously defined `client`'s `.moderations.create()` method. For the `input` argument, pass the `comment`. Assign to `moderation_output`.\n- Print the comment and moderation output.","metadata":{},"id":"e3b3e694-2176-4d46-91a2-7c17ef31b980","cell_type":"markdown"},{"source":"# Pick a comment.\ncomment = comments[2]\n\n# Define an OpenAI model. Assign to client.\nclient = openai.OpenAI()\n\n# Send the comment to the Moderation API.\nmoderation_output = client.moderations.create(input=comment)\n\n# Optionally print the comment.\nprint(comment)\n\n# Print the output.\nmoderation_output","metadata":{"executionCancelledAt":null,"executionTime":2729,"lastExecutedAt":1749074380545,"lastExecutedByKernel":"6915a89c-0b39-433b-a056-35cfb360a427","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Pick a comment.\ncomment = comments[2]\n\n# Define an OpenAI model. Assign to client.\nclient = openai.OpenAI()\n\n# Send the comment to the Moderation API.\nmoderation_output = client.moderations.create(input=comment)\n\n# Optionally print the comment.\nprint(comment)\n\n# Print the output.\nmoderation_output","outputsMetadata":{"0":{"height":80,"type":"stream"}}},"id":"306b2862-bcdb-4e67-add4-c776ddc14c5f","cell_type":"code","execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":"Lol China not going to make a dent in the global scale. Wake me up when America’s housing market is about to implode that’s when I’m pulling out all my investments. Because the world is going to burn.\n\n"},{"output_type":"execute_result","data":{"text/plain":"ModerationCreateResponse(id='modr-BeqR0BvL0oy9c4v05fLcnwSI6Ke1Y', model='text-moderation-007', results=[Moderation(categories=Categories(harassment=True, harassment_threatening=False, hate=False, hate_threatening=False, self_harm=False, self_harm_instructions=False, self_harm_intent=False, sexual=False, sexual_minors=False, violence=False, violence_graphic=False, self-harm=False, sexual/minors=False, hate/threatening=False, violence/graphic=False, self-harm/intent=False, self-harm/instructions=False, harassment/threatening=False), category_scores=CategoryScores(harassment=0.5870464444160461, harassment_threatening=0.035818107426166534, hate=0.03748295083642006, hate_threatening=0.008557282388210297, self_harm=3.218484198441729e-05, self_harm_instructions=2.1505543372768443e-06, self_harm_intent=1.1581191756704357e-05, sexual=3.791242761508329e-06, sexual_minors=4.0563273273619416e-07, violence=0.06111923232674599, violence_graphic=0.0001648496399866417, self-harm=3.218484198441729e-05, sexual/minors=4.0563273273619416e-07, hate/threatening=0.008557282388210297, violence/graphic=0.0001648496399866417, self-harm/intent=1.1581191756704357e-05, self-harm/instructions=2.1505543372768443e-06, harassment/threatening=0.035818107426166534), flagged=True)])"},"metadata":{},"execution_count":23}]},{"source":"We can analyze the output above to determine whether the comment has been deemed explicit or not. The `\"flagged\"` boolean will show us if any (at least one) category has been flagged, and underneath we can see which categories have been flagged.","metadata":{},"id":"1ec05e3a-144a-4abd-8a1c-02b72e2cb41f","cell_type":"markdown"},{"source":"The moderation scores for each category can be retrieved to explore why the text was flagged as inappropriate. It's slightly tedious code, but can be reused exactly whenever you use the moderation API.","metadata":{},"id":"9fa1e045-3679-4d6b-b97d-e7bf27bd5a83","cell_type":"markdown"},{"source":"# Run this code to see the scores\npd.DataFrame(moderation_output.results[0].dict())[[\"categories\", \"category_scores\"]]","metadata":{"executionCancelledAt":null,"executionTime":59,"lastExecutedAt":1749074380604,"lastExecutedByKernel":"6915a89c-0b39-433b-a056-35cfb360a427","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Run this code to see the scores\npd.DataFrame(moderation_output.results[0].dict())[[\"categories\", \"category_scores\"]]","outputsMetadata":{"0":{"height":550,"type":"dataFrame","tableState":{"customFilter":{"const":{"type":"boolean","valid":true,"value":true},"id":"f3b752a8-642c-4da5-85cc-0a713db1ad8f","nodeType":"const"}}}}},"id":"8271e107-d1da-4a84-8557-e163f7a1f103","cell_type":"code","execution_count":24,"outputs":[{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"index","type":"string"},{"name":"categories","type":"boolean"},{"name":"category_scores","type":"number"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":{"index":["harassment","harassment_threatening","hate","hate_threatening","self_harm","self_harm_instructions","self_harm_intent","sexual","sexual_minors","violence","violence_graphic","self-harm","sexual/minors","hate/threatening","violence/graphic","self-harm/intent","self-harm/instructions","harassment/threatening"],"categories":[true,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false,false],"category_scores":[0.5870464444,0.0358181074,0.0374829508,0.0085572824,0.0000321848,0.0000021506,0.0000115812,0.0000037912,4.056e-7,0.0611192323,0.0001648496,0.0000321848,4.056e-7,0.0085572824,0.0001648496,0.0000115812,0.0000021506,0.0358181074]}},"total_rows":18,"truncation_type":null},"text/plain":"                        categories  category_scores\nharassment                    True     5.870464e-01\nharassment_threatening       False     3.581811e-02\nhate                         False     3.748295e-02\nhate_threatening             False     8.557282e-03\nself_harm                    False     3.218484e-05\nself_harm_instructions       False     2.150554e-06\nself_harm_intent             False     1.158119e-05\nsexual                       False     3.791243e-06\nsexual_minors                False     4.056327e-07\nviolence                     False     6.111923e-02\nviolence_graphic             False     1.648496e-04\nself-harm                    False     3.218484e-05\nsexual/minors                False     4.056327e-07\nhate/threatening             False     8.557282e-03\nviolence/graphic             False     1.648496e-04\nself-harm/intent             False     1.158119e-05\nself-harm/instructions       False     2.150554e-06\nharassment/threatening       False     3.581811e-02","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>categories</th>\n      <th>category_scores</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>harassment</th>\n      <td>True</td>\n      <td>5.870464e-01</td>\n    </tr>\n    <tr>\n      <th>harassment_threatening</th>\n      <td>False</td>\n      <td>3.581811e-02</td>\n    </tr>\n    <tr>\n      <th>hate</th>\n      <td>False</td>\n      <td>3.748295e-02</td>\n    </tr>\n    <tr>\n      <th>hate_threatening</th>\n      <td>False</td>\n      <td>8.557282e-03</td>\n    </tr>\n    <tr>\n      <th>self_harm</th>\n      <td>False</td>\n      <td>3.218484e-05</td>\n    </tr>\n    <tr>\n      <th>self_harm_instructions</th>\n      <td>False</td>\n      <td>2.150554e-06</td>\n    </tr>\n    <tr>\n      <th>self_harm_intent</th>\n      <td>False</td>\n      <td>1.158119e-05</td>\n    </tr>\n    <tr>\n      <th>sexual</th>\n      <td>False</td>\n      <td>3.791243e-06</td>\n    </tr>\n    <tr>\n      <th>sexual_minors</th>\n      <td>False</td>\n      <td>4.056327e-07</td>\n    </tr>\n    <tr>\n      <th>violence</th>\n      <td>False</td>\n      <td>6.111923e-02</td>\n    </tr>\n    <tr>\n      <th>violence_graphic</th>\n      <td>False</td>\n      <td>1.648496e-04</td>\n    </tr>\n    <tr>\n      <th>self-harm</th>\n      <td>False</td>\n      <td>3.218484e-05</td>\n    </tr>\n    <tr>\n      <th>sexual/minors</th>\n      <td>False</td>\n      <td>4.056327e-07</td>\n    </tr>\n    <tr>\n      <th>hate/threatening</th>\n      <td>False</td>\n      <td>8.557282e-03</td>\n    </tr>\n    <tr>\n      <th>violence/graphic</th>\n      <td>False</td>\n      <td>1.648496e-04</td>\n    </tr>\n    <tr>\n      <th>self-harm/intent</th>\n      <td>False</td>\n      <td>1.158119e-05</td>\n    </tr>\n    <tr>\n      <th>self-harm/instructions</th>\n      <td>False</td>\n      <td>2.150554e-06</td>\n    </tr>\n    <tr>\n      <th>harassment/threatening</th>\n      <td>False</td>\n      <td>3.581811e-02</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{"application/com.datacamp.data-table.v2+json":{"status":"success"}},"execution_count":24}]},{"source":"## Summary\n\nHere's a quick recap of what we've done:\n\n- **Prompt Engineering**: Mastered essential tricks and optimizations to enhance the performance of your prompts.\n- **Prompt Templates**: Set up and utilized prompt templates for consistent and efficient prompt generation.\n- **LLMChains**: Leveraged LLMChains to streamline the process of chaining together multiple language model calls.\n- **Output Parsing**: Used LangChain's output parsing capabilities to convert AI-generated text into Python objects for downstream applications.\n- **Agents and Tools**: Integrated LangChain Agents and Tools to extend the functionality of your generative AI projects.\n- **Moderation API**: Employed the Moderation API to filter and moderate user input, ensuring safe and appropriate interactions.\n\nWith these skills, you are well-prepared to tackle more advanced modules and projects. Best of luck in your continued learning journey!\n```","metadata":{},"id":"6c9ba593-30fa-43b5-9b18-2bd6c7e4087e","cell_type":"markdown"},{"source":"## Conclusion\n\nIn this project, we embarked on an insightful journey through the landscape of generative AI, leveraging the power of LangChain and various other tools to analyze and moderate user-generated content. Our exploration was not just about understanding the data but also about honing a diverse set of skills that are crucial for any AI enthusiast. Here’s a summary of our accomplishments and the skills we developed:\n\n### Data Analysis and Moderation\nWe started by analyzing a dataset containing company names, sentiments, and headlines. This allowed us to understand the context and sentiment behind each headline, providing a foundation for more advanced AI applications. We then integrated the Moderation API to ensure that the content we analyzed and generated adhered to community guidelines, showcasing our ability to implement ethical AI practices.\n\n### Prompt Engineering and Optimization\nOne of the key skills we developed was prompt engineering. We learned how to craft effective prompts that guide the AI to produce the desired output. This involved understanding the nuances of language and the importance of context, which are essential for creating reliable and accurate AI models.\n\n### Setting Up Prompt Templates\nWe explored the creation of prompt templates, which are reusable components that streamline the process of generating AI responses. This not only improved our efficiency but also ensured consistency in the outputs, a critical aspect when scaling AI solutions.\n\n### Utilizing LLMChains\nBy using LLMChains, we were able to chain together multiple language models to perform complex tasks. This demonstrated our ability to build sophisticated AI pipelines that can handle a variety of inputs and produce coherent, contextually relevant outputs.\n\n### Output Parsing and Python Integration\nWe delved into LangChain’s output parsing capabilities, learning how to convert AI-generated text into Python objects. This skill is invaluable for integrating AI outputs into larger systems, enabling seamless interaction between AI models and other software components.\n\n### Implementing LangChain Agents and Tools\nOur journey also included the use of LangChain Agents and Tools, which added a layer of functionality to our AI projects. These tools allowed us to extend the capabilities of our models, making them more versatile and powerful.\n\n### Leveraging the Moderation API\nFinally, we leveraged the Moderation API to filter user input, ensuring that our AI models operate within ethical boundaries. This step underscored the importance of responsible AI development and our commitment to creating safe and inclusive AI solutions.","metadata":{},"cell_type":"markdown","id":"e948e80e-8e82-4a4b-b306-0d322c7b0698"}],"metadata":{"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}