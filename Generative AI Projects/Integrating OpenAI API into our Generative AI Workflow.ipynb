{"cells":[{"source":"## Integrating OpenAI API into our Generative AI Workflow\n\nLeveraging the OpenAI API opens up a world of possibilities for programming and automation workflows, far beyond simple chat interactions. This guide will walk you through the process of integrating the OpenAI API into your projects, enhancing your generative AI portfolio. We'll cover:\n\n- **Setting Up Your OpenAI Developer Account**: Learn how to create and configure your OpenAI developer account, and integrate it with your development environment.\n- **Calling the Chat Functionality**: Understand how to make API calls to utilize the chat functionality of OpenAI's models.\n- **Extracting Response Text**: Discover methods to parse and extract meaningful responses from the API output.\n- **Maintaining a Conversation**: Implement techniques to hold longer, context-aware conversations with the AI.\n- **Combining OpenAI API with Other APIs**: Explore how to integrate the OpenAI API with other APIs to build more complex and powerful applications.\n\nBy the end of this guide, we will have a solid foundation for incorporating OpenAI's capabilities into your own projects, making your generative AI portfolio more robust and versatile.","metadata":{},"id":"0c5dc78a-2c33-4b6e-a3b8-9dc7a61d29ac","cell_type":"markdown"},{"source":"## Step 0: Setup","metadata":{},"id":"4b339dfc-8612-4ca1-9613-4f030f479b6a","cell_type":"markdown"},{"source":"To use GPT, we need to import the `os` and `openai` packages, and some functions from `IPython.display` to render Markdown. A later task will also use Yahoo! Finance data via the `yfinance` package.\n\nWe also need to put the environment variable we just created in a place that the `openai` package can see it.","metadata":{},"id":"4e144991-0b50-4a2b-9ab7-708e34ff53d0","cell_type":"markdown"},{"source":"- Import the `os` package.\n- Import the `openai` package.\n- Import the `yfinance` package with the alias `yf`.\n- From the `IPython.display` package, import `display` and `Markdown`.\n- Set `openai.api_key` to the `OPENAI` environment variable.","metadata":{},"id":"d85e559b-6e89-424e-8bf7-274d7c951435","cell_type":"markdown"},{"source":"# Import the os package\nimport os\n\n# Import the openai package\nfrom openai import OpenAI\n\n# Import yfinance as yf\nimport yfinance as yf\n\n# From the IPython.display package, import display and Markdown\nfrom IPython.display import display, Markdown\n\n# Set openai.api_key to the OPENAI environment variable\nopenai_api_key = os.environ[\"OPENAI_API_KEY\"]\n\n# we set OpenaAI client \nclient = OpenAI()","metadata":{"executionTime":51,"lastSuccessfullyExecutedCode":"# Import the os package\nimport os\n\n# Import the openai package\nfrom openai import OpenAI\n\n# Import yfinance as yf\nimport yfinance as yf\n\n# From the IPython.display package, import display and Markdown\nfrom IPython.display import display, Markdown\n\n# Set openai.api_key to the OPENAI environment variable\nopenai_api_key = os.environ[\"OPENAI_API_KEY\"]\n\n# we set OpenaAI client \nclient = OpenAI()","executionCancelledAt":null,"lastExecutedAt":1749588599425,"lastExecutedByKernel":"fcab8916-92c9-44c3-80b8-ded4000e4f8c","lastScheduledRunId":null},"id":"6b8a7596-d34b-419b-baf3-004e48f1aca5","cell_type":"code","execution_count":62,"outputs":[]},{"source":"## Step 1: Get GPT to create a dataset","metadata":{},"id":"1ee98f37-16cf-4cf4-80f6-ac5fa2c666b5","cell_type":"markdown"},{"source":"It's time to chat! Having a conversation with GPT involves a single function call of this form.\n\n```python\nresponse = openai.ChatCompletion.create(\n    model=\"MODEL_NAME\",\n    messages=[\n        {\"role\": \"system\", \"content\": 'SPECIFY HOW THE AI ASSISTANT SHOULD BEHAVE'},\n        {\"role\": \"user\", \"content\": 'SPECIFY WANT YOU WANT THE AI ASSISTANT TO SAY'}\n    ]\n)\n```\n\nThere are a few things to unpack here.\n\nThe model names are listed in the [Model Overview](https://platform.openai.com/docs/models/overview) page of the developer documentation. Today we'll be using `gpt-3.5-turbo`, which is the latest model used by ChatGPT that has broad public API access. \n\nIf you have access to GPT-4, you can use that instead by setting `model=\"gpt-4\"`, though note that the price is 15 times higher.\n\nThere are three types of message, documented in the [Introduction](https://platform.openai.com/docs/guides/chat/introduction) to the Chat documentation:\n\n- `system` messages describe the behavior of the AI assistant. If you don't know what you want, try \"You are a helpful assistant\".\n- `user` messages describe what you want the AI assistant to say. We'll cover examples of this today.\n- `assistant` messages describe previous responses in the conversation. We'll cover how to have an interactive conversation in later tasks. \n\nThe first message should be a system message. Additional messages should alternate between user and assistant.","metadata":{},"id":"9e1baa5c-0e61-41ad-b757-aab82756d8f2","cell_type":"markdown"},{"source":"### Define the system message, `system_msg` as\n\n> 'You are a helpful assistant who understands data science.'\n\n### Define the user message, `user_msg` as: \n\n> 'Create a small dataset of data about people. The format of the dataset should be a data frame with 5 rows and 3 columns. The columns should be called \"name\", \"height_cm\", and \"eye_color\". The \"name\" column should contain randomly chosen first names. The \"height_cm\" column should contain randomly chosen heights, given in centimeters. The \"eye_color\" column should contain randomly chosen eye colors, taken from a choice of \"brown\", \"blue\", and \"green\". Provide Python code to generate the dataset, then provide the output in the format of a markdown table.'\n\n- Ask GPT to create a dataset using the `gpt-3.5-turbo` model. Assign to `response`.\n","metadata":{},"id":"437acbc2-db60-4feb-ac7f-19b50749d297","cell_type":"markdown"},{"source":"import openai\n\n# Define the system message\nsystem_msg = 'You are a helpful assistant who understands data science'\n\n# Define the user message\nuser_msg = 'Create a small dataset of data about people. The format of the dataset should be a data frame with 5 rows and 3 columns. The columns should be called \"name\", \"height_cm\", and \"eye_color\". The \"name\" column should contain randomly chosen first names. The \"height_cm\" column should contain randomly chosen heights, given in centimeters. The \"eye_color\" column should contain randomly chosen eye colors, taken from a choice of \"brown\", \"blue\", and \"green\". Provide Python code to generate the dataset, then provide the output in the format of a markdown table.'\n\n# Create a dataset using GPT\nresponse =  client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\"role\": \"system\", \"content\": system_msg},\n        {\"role\": \"user\", \"content\": user_msg}\n    ]\n)\n\nprint(\"Full Response Answer is:\\n\")\nprint(response)","metadata":{"executionTime":2443,"lastSuccessfullyExecutedCode":"import openai\n\n# Define the system message\nsystem_msg = 'You are a helpful assistant who understands data science'\n\n# Define the user message\nuser_msg = 'Create a small dataset of data about people. The format of the dataset should be a data frame with 5 rows and 3 columns. The columns should be called \"name\", \"height_cm\", and \"eye_color\". The \"name\" column should contain randomly chosen first names. The \"height_cm\" column should contain randomly chosen heights, given in centimeters. The \"eye_color\" column should contain randomly chosen eye colors, taken from a choice of \"brown\", \"blue\", and \"green\". Provide Python code to generate the dataset, then provide the output in the format of a markdown table.'\n\n# Create a dataset using GPT\nresponse =  client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    messages=[\n        {\"role\": \"system\", \"content\": system_msg},\n        {\"role\": \"user\", \"content\": user_msg}\n    ]\n)\n\nprint(\"Full Response Answer is:\\n\")\nprint(response)","executionCancelledAt":null,"lastExecutedAt":1749588601868,"lastExecutedByKernel":"fcab8916-92c9-44c3-80b8-ded4000e4f8c","lastScheduledRunId":null},"id":"c8c671da-51d6-4d7d-9769-393312ebb8cd","cell_type":"code","execution_count":63,"outputs":[{"output_type":"stream","name":"stdout","text":"Full Response Answer is:\n\nChatCompletion(id='chatcmpl-Bh0CtNBBGV7KKwmkNGI8DJVfva7iV', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Here is the Python code to create the dataset and then display it in a markdown table:\\n\\n```python\\nimport pandas as pd\\nimport random\\n\\n# Create the dataset\\ndata = {\\n    \"name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\"],\\n    \"height_cm\": [random.randint(150, 190) for _ in range(5)],\\n    \"eye_color\": random.choices([\"brown\", \"blue\", \"green\"], k=5)\\n}\\n\\ndf = pd.DataFrame(data)\\n\\n# Display the dataset in a markdown table\\nprint(df.to_markdown(index=False))\\n```\\n\\nOutput (in the format of a markdown table):\\n\\n| name    |   height_cm | eye_color   |\\n|:--------|------------:|:------------|\\n| Alice   |         188 | brown       |\\n| Bob     |         174 | blue        |\\n| Charlie |         177 | green       |\\n| David   |         151 | brown       |\\n| Eve     |         184 | green       |\\n```', refusal=None, role='assistant', function_call=None, tool_calls=None, annotations=[]))], created=1749588599, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=211, prompt_tokens=142, total_tokens=353, completion_tokens_details=CompletionTokensDetails(reasoning_tokens=0, audio_tokens=0, accepted_prediction_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details={'cached_tokens': 0, 'audio_tokens': 0}), _request_id='req_36857cbf06636209b6e5c80678292a1d', __exclude_fields__={'_request_id', '__exclude_fields__'})\n"}]},{"source":"## Step 2: Check the response is OK","metadata":{},"id":"d818b7bc-1891-4908-9ed3-81ecfe65f20b","cell_type":"markdown"},{"source":"API calls are \"risky\" because problems can occur outside of your notebook, like internet connectivity issues, or a problem with the server sending you data, or because you ran out of API credit. You should check that the response you get is OK.\n\nGPT models return a status code with one of four values, documented in the [Response format](https://platform.openai.com/docs/guides/chat/response-format) section of the Chat documentation.\n\n- `stop`: API returned complete model output\n- `length`: Incomplete model output due to max_tokens parameter or token limit\n- `content_filter`: Omitted content due to a flag from our content filters\n- `null`: API response still in progress or incomplete\n\nThe GPT API sends data to Python in JSON format, so the response variable contains deeply nested lists and dictionaries. It's a bit of a pain to work with!\n\nFor a response variable named `response`, the status code is stored in `response[\"choices\"][0][\"finish_reason\"]`.","metadata":{},"id":"0aef6080-50bb-45b0-8b0a-62e26cd7cd08","cell_type":"markdown"},{"source":"If you prefer to work with dataframes rather than nested lists and dictionaries, you can flatten the output to a single row dataframe with the following code.\n\n```python\nimport pandas as pd\npd.json_normalize(response, \"choices\", ['id', 'object', 'created', 'model', 'usage'])\n```","metadata":{},"id":"0d4b818b-186e-4b24-b461-6ed465565584","cell_type":"markdown"},{"source":"### Check the status code of the `response` variable.","metadata":{},"id":"05ebd19c-ecbc-4cf1-853e-6563222de7f1","cell_type":"markdown"},{"source":"# Check the status code of the response variable\nprint(\"Reason of the API Stop:\\n\")\nprint(response.choices[0].finish_reason)\n\nif response.choices[0].finish_reason == \"stop\":\n    print(\"OpenAI works perect, we get the expected answer. Well donde Santiago\")","metadata":{"executionTime":45,"lastSuccessfullyExecutedCode":"# Check the status code of the response variable\nprint(\"Reason of the API Stop:\\n\")\nprint(response.choices[0].finish_reason)\n\nif response.choices[0].finish_reason == \"stop\":\n    print(\"OpenAI works perect, we get the expected answer. Well donde Santiago\")","executionCancelledAt":null,"lastExecutedAt":1749588601913,"lastExecutedByKernel":"fcab8916-92c9-44c3-80b8-ded4000e4f8c","lastScheduledRunId":null,"outputsMetadata":{"0":{"height":616,"type":"stream"}}},"id":"8fc5d778-266e-4858-b36f-6be9e6359569","cell_type":"code","execution_count":64,"outputs":[{"output_type":"stream","name":"stdout","text":"Reason of the API Stop:\n\nstop\nOpenAI works perect, we get the expected answer. Well donde Santiago\n"}]},{"source":"## Step 3: Extract the AI assistant's message","metadata":{},"id":"1084f3d6-0006-459c-bf9a-f071a2d3ec5a","cell_type":"markdown"},{"source":"Buried within the response variable is the text we asked GPT to generate. Luckily, it's always in the same place.\n\n`response[\"choices\"][0][\"message\"][\"content\"]`\n\nThe response content can be printed as usual with `print(content)`, but it's Markdown content, which Jupyter notebooks can render, via `display(Markdown(content))`.","metadata":{},"id":"9d74095e-10e9-40fe-97bc-5d9f89a576b3","cell_type":"markdown"},{"source":"- Print the content generated by GPT.\n\n- Render the Markdown content generated by GPT.\n\n- Read the code that was generated. Does it look correct?\n\n- Read the dataset that was generated. Does it match the specifications?","metadata":{},"id":"0b7ae748-08d4-435d-916c-8ec618e56324","cell_type":"markdown"},{"source":"# Print the content generated by GPT.\nprint(response.choices[0].message.content)","metadata":{"executionTime":48,"lastSuccessfullyExecutedCode":"# Print the content generated by GPT.\nprint(response.choices[0].message.content)","executionCancelledAt":null,"lastExecutedAt":1749588601961,"lastExecutedByKernel":"fcab8916-92c9-44c3-80b8-ded4000e4f8c","lastScheduledRunId":null},"id":"aaa8badc-121b-4e40-a4f9-d14ded814905","cell_type":"code","execution_count":65,"outputs":[{"output_type":"stream","name":"stdout","text":"Here is the Python code to create the dataset and then display it in a markdown table:\n\n```python\nimport pandas as pd\nimport random\n\n# Create the dataset\ndata = {\n    \"name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\"],\n    \"height_cm\": [random.randint(150, 190) for _ in range(5)],\n    \"eye_color\": random.choices([\"brown\", \"blue\", \"green\"], k=5)\n}\n\ndf = pd.DataFrame(data)\n\n# Display the dataset in a markdown table\nprint(df.to_markdown(index=False))\n```\n\nOutput (in the format of a markdown table):\n\n| name    |   height_cm | eye_color   |\n|:--------|------------:|:------------|\n| Alice   |         188 | brown       |\n| Bob     |         174 | blue        |\n| Charlie |         177 | green       |\n| David   |         151 | brown       |\n| Eve     |         184 | green       |\n```\n"}]},{"source":"# Render the Markdown content generated by GPT\nmarkdown_style_response = response.choices[0].message.content\n\ndisplay(Markdown(markdown_style_response))","metadata":{"executionTime":48,"lastSuccessfullyExecutedCode":"# Render the Markdown content generated by GPT\nmarkdown_style_response = response.choices[0].message.content\n\ndisplay(Markdown(markdown_style_response))","executionCancelledAt":null,"lastExecutedAt":1749588602009,"lastExecutedByKernel":"fcab8916-92c9-44c3-80b8-ded4000e4f8c","lastScheduledRunId":null},"id":"609d3d89-2abe-4962-8d2f-a5e6a175d501","cell_type":"code","execution_count":66,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Here is the Python code to create the dataset and then display it in a markdown table:\n\n```python\nimport pandas as pd\nimport random\n\n# Create the dataset\ndata = {\n    \"name\": [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\"],\n    \"height_cm\": [random.randint(150, 190) for _ in range(5)],\n    \"eye_color\": random.choices([\"brown\", \"blue\", \"green\"], k=5)\n}\n\ndf = pd.DataFrame(data)\n\n# Display the dataset in a markdown table\nprint(df.to_markdown(index=False))\n```\n\nOutput (in the format of a markdown table):\n\n| name    |   height_cm | eye_color   |\n|:--------|------------:|:------------|\n| Alice   |         188 | brown       |\n| Bob     |         174 | blue        |\n| Charlie |         177 | green       |\n| David   |         151 | brown       |\n| Eve     |         184 | green       |\n```"},"metadata":{}}]},{"source":"## Lets use a helper function","metadata":{},"id":"c776c0b9-05c8-4e75-a2fa-53147b7752e9","cell_type":"markdown"},{"source":"You need to write a lot of repetitive boilerplate code to do these three simple things. Having a wrapper function to abstract away the boring bits is useful. That way we can focus on data science use cases.\n\nHopefully OpenAI will improve the interface to their Python package so this sort of thing is built-in. In the meantime, feel free to use this in your own code.\n\nThe function takes 2 arguments.\n\n- `system`: A string containing the system message.\n- `user_assistant`: An array of strings that alternate user message then assistant message.\n\nThe return value is the generated content.","metadata":{},"id":"791988c1-13e8-45d4-b7a4-56402260c535","cell_type":"markdown"},{"source":"### Run the next cell so you have access to the function.","metadata":{},"id":"297316fe-89f4-4e7e-98db-1ed6c86dda0a","cell_type":"markdown"},{"source":"def chat(system, user_assistant):\n    assert isinstance(system, str), \"`system` should be a string\"\n    assert isinstance(user_assistant, list), \"`user_assistant` should be a list\"\n    system_msg = [{\"role\": \"system\", \"content\": system}]\n    user_assistant_msgs = [\n        {\"role\": \"assistant\", \"content\": user_assistant[i]} if i % 2 else {\"role\": \"user\", \"content\": user_assistant[i]} \n        for i in range(len(user_assistant))\n    ]\n    msgs = system_msg + user_assistant_msgs\n    response = client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        messages=msgs\n    )\n    status_code = response.choices[0].finish_reason\n    assert status_code == \"stop\", f\"The status code was {status_code}.\"\n    return response.choices[0].message.content\n\n# call the function\nchat(\"You are a machine learning expert who writes tersely.\", [\"Explain what a support vector machine model is.\"])","metadata":{"executionTime":1009,"lastSuccessfullyExecutedCode":"def chat(system, user_assistant):\n    assert isinstance(system, str), \"`system` should be a string\"\n    assert isinstance(user_assistant, list), \"`user_assistant` should be a list\"\n    system_msg = [{\"role\": \"system\", \"content\": system}]\n    user_assistant_msgs = [\n        {\"role\": \"assistant\", \"content\": user_assistant[i]} if i % 2 else {\"role\": \"user\", \"content\": user_assistant[i]} \n        for i in range(len(user_assistant))\n    ]\n    msgs = system_msg + user_assistant_msgs\n    response = client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        messages=msgs\n    )\n    status_code = response.choices[0].finish_reason\n    assert status_code == \"stop\", f\"The status code was {status_code}.\"\n    return response.choices[0].message.content\n\n# call the function\nchat(\"You are a machine learning expert who writes tersely.\", [\"Explain what a support vector machine model is.\"])","executionCancelledAt":null,"lastExecutedAt":1749588603018,"lastExecutedByKernel":"fcab8916-92c9-44c3-80b8-ded4000e4f8c","lastScheduledRunId":null},"id":"7c230c3b-0442-4f10-8e0e-a55c5829e8a5","cell_type":"code","execution_count":67,"outputs":[{"output_type":"execute_result","data":{"text/plain":"'Support Vector Machine (SVM) is a supervised machine learning algorithm that is used for classification and regression tasks. It works by finding the hyperplane that best separates the classes in the feature space.'"},"metadata":{},"execution_count":67}]},{"source":"Here is a check to make sure the function works.","metadata":{},"id":"43f72850-3b02-416d-b9f3-70a70d287861","cell_type":"markdown"},{"source":"response_fn_test = chat(\n    \"You are a machine learning expert who writes tersely.\", \n    [\"Explain what a support vector machine model is.\"]\n)\ndisplay(Markdown(response_fn_test))","metadata":{"executionTime":840,"lastSuccessfullyExecutedCode":"response_fn_test = chat(\n    \"You are a machine learning expert who writes tersely.\", \n    [\"Explain what a support vector machine model is.\"]\n)\ndisplay(Markdown(response_fn_test))","executionCancelledAt":null,"lastExecutedAt":1749588603858,"lastExecutedByKernel":"fcab8916-92c9-44c3-80b8-ded4000e4f8c","lastScheduledRunId":null},"id":"20e58a34-7c09-44e3-aa60-56cf1954c182","cell_type":"code","execution_count":68,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Support vector machine is a supervised machine learning algorithm used for classification and regression tasks. It works by finding the hyperplane that best separates different classes in the feature space."},"metadata":{}}]},{"source":"### Pro Tip\n\nIn the system message for that check to make sure the function works correctly, I told the AI that it \"writes tersely\". This reduces the amount of output it generates, saving you some credits. You won't always want a terse output, but it's useful if you are just testing things.\n\n**When you don't care too much about the style of the output, include a command to \"write tersely\" in the system message.**","metadata":{},"id":"8078549e-771a-4174-a992-7290a1acd2e3","cell_type":"markdown"},{"source":"## Step 4: Perform a calculation by reusing messages","metadata":{},"id":"c47d7d28-7882-4efe-91f5-13e0f55f00fc","cell_type":"markdown"},{"source":"The \"zero-shot\" case where the AI gives you the perfect response the first time is pretty rare. As with humans, you often need to have a longer conversation. This is where the user message-assistant message alternation comes in handy.","metadata":{},"id":"ccc45736-8708-49cb-95da-24f81de15c36","cell_type":"markdown"},{"source":"- Assign the content from the response in Task 1 to `assistant_msg`.\n\n- Define a new user message, `user_msg2` as follows.\n\n> 'Using the dataset you just created, write code to calculate the mean of the `height_cm` column. Also include the result of the calculation.'\n\n- Create a list of user and assistant messages from `user_msg`, `assistant_msg`, and `user_msg2`. Assign to `user_assistant_msgs`.\n\n- Get GPT to perform the request, using `system_msg` (from Task 1) and `user_assistant_msgs`. Assign to `response_calc`.\n\n- Read the code that was generated. Does it look correct?\n\n- Read the answer that was generated. Does it look correct?","metadata":{},"id":"39462527-da47-45c0-831c-494867a4c698","cell_type":"markdown"},{"source":"# Assign the content from the response in Task 1 to assistant_msg\nassistant_msg = response.choices[0].message.content\n\n# Define a new user message\nuser_msg2 = 'Using the dataset you just created, write code to calculate the mean of the `height_cm` column. Also include the result of the calculation.'\n\n# Create an array of user and assistant messages\nuser_assistant_msgs = [user_msg, assistant_msg, user_msg2]\n\n# Get GPT to perform the request\nresponse_calc = chat(system_msg, user_assistant_msgs)\n\n# Display the generated content\ndisplay(Markdown(response_calc))","metadata":{"executionTime":1441,"lastSuccessfullyExecutedCode":"# Assign the content from the response in Task 1 to assistant_msg\nassistant_msg = response.choices[0].message.content\n\n# Define a new user message\nuser_msg2 = 'Using the dataset you just created, write code to calculate the mean of the `height_cm` column. Also include the result of the calculation.'\n\n# Create an array of user and assistant messages\nuser_assistant_msgs = [user_msg, assistant_msg, user_msg2]\n\n# Get GPT to perform the request\nresponse_calc = chat(system_msg, user_assistant_msgs)\n\n# Display the generated content\ndisplay(Markdown(response_calc))","executionCancelledAt":null,"lastExecutedAt":1749588605299,"lastExecutedByKernel":"fcab8916-92c9-44c3-80b8-ded4000e4f8c","lastScheduledRunId":null},"id":"869fb5f0-4f08-4d7e-98f2-3e9162eb1828","cell_type":"code","execution_count":69,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"Here is the Python code to calculate the mean of the `height_cm` column in the dataset:\n\n```python\nmean_height = df['height_cm'].mean()\nprint(f\"The mean height in the dataset is: {mean_height:.2f} cm\")\n```\n\nResult:\n```\nThe mean height in the dataset is: 174.80 cm\n```"},"metadata":{}}]},{"source":"## Why should you care about the API?","metadata":{},"id":"f7ceafc5-ee51-4301-9163-43a602094887","cell_type":"markdown"},{"source":"At this point, you know pretty much everything about how to use the OpenAI API to generate content with GPT. However, you might wonder \"**why should I bother using the API instead of the web interface?**\".\n\nAPIs are great for automation in data pipelines or inside software. Some possible data science users of the API include:\n\n- Pull in data (from a database, another API, or wherever), and ask GPT to summarize it or generate a report about it.\n- Use the [linkedin-api-client](https://pypi.org/project/linkedin-api-client/) LinkedIn API package to pull in someone's profile, and ask GPT to personalize email text based on that information.\n- Use the [scholarly](https://pypi.org/project/scholarly/) Google Scholar API package to pull in journal paper details, then get GPT to summarize the results.\n- Embed the API in a dashboard to automatically provide a text summary of the results.\n- Provide a natural language interface to your data mart.","metadata":{},"id":"4ab12485-b071-421e-a609-cc3137bc775e","cell_type":"markdown"},{"source":"## Step 5: Get Silicon Valley Bank stock data from Yahoo! Finance","metadata":{},"id":"28dd3942-36aa-4cba-be1a-bc78d4015e95","cell_type":"markdown"},{"source":"Lets try an example of automatically analyzing some stock data. In this case, we'll look at Silicon Valley Bank (ticker `SIVB`) from the last month. The data is available from Yahoo! Finance, and can be imported into Python via the `yfinance` package.\n\nTo get recent stock history for the last `N` months, the code pattern is\n\n```python\nticker = yf.Ticker(\"TICKERNAME\")\nticker_history = ticker.history(period=\"Nmo\")\n```\n\nIn general, we should try to minimize the amount of data sent to the API (network traffic is slow), so we'll stick to looking at the `Close` column, which contains the stock price at the close of the day. Further, we'll round the prices to the nearest cent (2 decimal places).","metadata":{},"id":"85794705-3126-4ade-b628-4e2e76e4b278","cell_type":"markdown"},{"source":"- Create a Ticker object for `SIVB`. Assign to `sivb`.\n\n- Get the stock history for SIVB for the period of 1 month (`\"1mo\"`). Assign to `sivb_history`.\n\n- Select the `Close` column and round it to two decimal places. Assign to `sivb_close`.","metadata":{},"id":"73e333b0-fc64-43cc-ba33-3ce62d6c8fad","cell_type":"markdown"},{"source":"# Create a Ticker object for SIVB\nsivb = yf.Ticker(\"SIVB\")\n\n# Get the stock history for SIVB for the period of 1 month\nsivb_history = sivb.history(period=\"1mo\")\nprint(sivb_history)\n\n# Select the Close column and round it to two decimal places\nsivb_close = sivb_history[[\"Close\"]].round(2)\nsivb_close","metadata":{"executionTime":65,"lastSuccessfullyExecutedCode":"# Create a Ticker object for SIVB\nsivb = yf.Ticker(\"SIVB\")\n\n# Get the stock history for SIVB for the period of 1 month\nsivb_history = sivb.history(period=\"1mo\")\nprint(sivb_history)\n\n# Select the Close column and round it to two decimal places\nsivb_close = sivb_history[[\"Close\"]].round(2)\nsivb_close","executionCancelledAt":null,"lastExecutedAt":1749588605364,"lastExecutedByKernel":"fcab8916-92c9-44c3-80b8-ded4000e4f8c","lastScheduledRunId":null,"outputsMetadata":{"0":{"height":38,"type":"dataFrame"}}},"id":"f4d806fb-ef17-4486-8517-6c7b2c4baaf5","cell_type":"code","execution_count":70,"outputs":[{"output_type":"stream","name":"stdout","text":"Empty DataFrame\nColumns: [Open, High, Low, Close, Adj Close, Volume]\nIndex: []\n"},{"output_type":"execute_result","data":{"application/com.datacamp.data-table.v2+json":{"table":{"schema":{"fields":[{"name":"Date","type":"string"},{"name":"Close","type":"number"}],"primaryKey":["Date"],"pandas_version":"1.4.0"},"data":{"Date":[],"Close":[]}},"total_rows":0,"truncation_type":null},"text/plain":"Empty DataFrame\nColumns: [Close]\nIndex: []","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Close</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"},"metadata":{"application/com.datacamp.data-table.v2+json":{"status":"success"}},"execution_count":70}]},{"source":"## Step 6: Get GPT to write a financial report","metadata":{},"id":"0e002970-5b45-4c1d-b4fe-846555a7cd46","cell_type":"markdown"},{"source":"Now we have the data, we need to ask GPT to analyze it for us.\n\nOne thing that is useful to know is that you can convert a pandas dataframe into a string using the `.to_string()` method.","metadata":{},"id":"8a0d113a-128d-45a5-948a-ef4314290c0e","cell_type":"markdown"},{"source":"- Define a system message, `system_msg_sivb`, as:\n\n> 'You are a financial data expert who writes tersely.'\n\n- Define a user message, `user_msg_sivb`, as:\n\n> '''The closing prices for the Silicon Valley Bank stock (ticker SIVB) are provided below. Provide Python code to analyze the data including the following metrics:\n> \n> - The date of the highest closing price.\n> - The date of the lowest closing price.\n> - The date with the largest change from the previous closing price.\n> \n> Also write a short report that includes the results of the calculations.\n> \n> Here is the dataset:\n> \n> '''\n\n- Append `sivb_close`, converted to a string, to the user message.\n\n- Get GPT to generate a response from `system_msg_sivb` and `user_msg_sivb`. Assign to `response_sivb`.\n\n- Render the response as Markdown.\n\n- Read the code that was generated. Does it look correct?\n\n- Read the report that was generated. Does it look correct?","metadata":{},"id":"6e63bc3e-4956-4170-ba7b-c8ccaac3dd4f","cell_type":"markdown"},{"source":"# Define a system message\nsystem_msg_sivb = 'You are a financial data expert who writes tersely.'\n\n# Define a user message (including the dataset)\nuser_msg_sivb = '''The closing prices for the Silicon Valley Bank stock (ticker SIVB) are provided below. Provide Python code to analyze the data including the following metrics:\n\n- The date of the highest closing price.\n- The date of the lowest closing price.\n- The date with the largest change from the previous closing price.\n\nAlso write a short report that includes the results of the calculations.\n\nHere is the dataset:\n\n''' + sivb_close.to_string()\n\n# Get GPT to generate a response\nresponse_sivb = chat(system_msg_sivb, [user_msg_sivb])\n\n# Render the response as Markdown\ndisplay(Markdown(response_sivb))","metadata":{"executionTime":3033,"lastSuccessfullyExecutedCode":"# Define a system message\nsystem_msg_sivb = 'You are a financial data expert who writes tersely.'\n\n# Define a user message (including the dataset)\nuser_msg_sivb = '''The closing prices for the Silicon Valley Bank stock (ticker SIVB) are provided below. Provide Python code to analyze the data including the following metrics:\n\n- The date of the highest closing price.\n- The date of the lowest closing price.\n- The date with the largest change from the previous closing price.\n\nAlso write a short report that includes the results of the calculations.\n\nHere is the dataset:\n\n''' + sivb_close.to_string()\n\n# Get GPT to generate a response\nresponse_sivb = chat(system_msg_sivb, [user_msg_sivb])\n\n# Render the response as Markdown\ndisplay(Markdown(response_sivb))","executionCancelledAt":null,"lastExecutedAt":1749588608397,"lastExecutedByKernel":"fcab8916-92c9-44c3-80b8-ded4000e4f8c","lastScheduledRunId":null},"id":"8ad81e73-91b8-42ee-9674-ba2054bfc0da","cell_type":"code","execution_count":71,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"```python\nimport pandas as pd\n\n# Sample data\ndata = {'Close': [100.5, 102.3, 99.7, 105.2, 97.8]}\ndf = pd.DataFrame(data)\n\n# Calculate metrics\nhighest_closing_date = df.idxmax()['Close']\nlowest_closing_date = df.idxmin()['Close']\nlargest_change_date = df['Close'].diff().idxmax()\n\n# Report\nprint(\"Date of highest closing price:\", highest_closing_date)\nprint(\"Date of lowest closing price:\", lowest_closing_date)\nprint(\"Date with largest change from previous closing price:\", largest_change_date)\n```\n\n**Report:**\n- Date of highest closing price: Index\n- Date of lowest closing price: Index\n- Date with largest change from previous closing price: Index\n```"},"metadata":{}}]},{"source":"import pandas as pd\n\n# Sample data to create the DataFrame 'df'\ndata = {\n    'Date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05'],\n    'Close': [150, 152, 148, 153, 149]\n}\ndf = pd.DataFrame(data)\ndf['Date'] = pd.to_datetime(df['Date'])\ndf.set_index('Date', inplace=True)\n\n# Find date of highest closing price\nmax_close_date = df['Close'].idxmax()\n\n# Find date of lowest closing price\nmin_close_date = df['Close'].idxmin()\n\n# Calculate change from previous day's closing price\ndf['Prev Close'] = df['Close'].shift(1)\ndf['Change'] = df['Close'] - df['Prev Close']\nmax_change_date = df['Change'].idxmax()\n\nreport = f\"Analysis report:\\n- Date of highest closing price: {max_close_date}\\n- Date of lowest closing price: {min_close_date}\\n- Date with largest change from previous closing price: {max_change_date}.\"\nprint(report)","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1749588608449,"lastExecutedByKernel":"fcab8916-92c9-44c3-80b8-ded4000e4f8c","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import pandas as pd\n\n# Sample data to create the DataFrame 'df'\ndata = {\n    'Date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05'],\n    'Close': [150, 152, 148, 153, 149]\n}\ndf = pd.DataFrame(data)\ndf['Date'] = pd.to_datetime(df['Date'])\ndf.set_index('Date', inplace=True)\n\n# Find date of highest closing price\nmax_close_date = df['Close'].idxmax()\n\n# Find date of lowest closing price\nmin_close_date = df['Close'].idxmin()\n\n# Calculate change from previous day's closing price\ndf['Prev Close'] = df['Close'].shift(1)\ndf['Change'] = df['Close'] - df['Prev Close']\nmax_change_date = df['Change'].idxmax()\n\nreport = f\"Analysis report:\\n- Date of highest closing price: {max_close_date}\\n- Date of lowest closing price: {min_close_date}\\n- Date with largest change from previous closing price: {max_change_date}.\"\nprint(report)"},"cell_type":"code","id":"dc2afb2b-1c70-48d4-afc1-bc10382ea49b","outputs":[{"output_type":"stream","name":"stdout","text":"Analysis report:\n- Date of highest closing price: 2023-01-04 00:00:00\n- Date of lowest closing price: 2023-01-03 00:00:00\n- Date with largest change from previous closing price: 2023-01-04 00:00:00.\n"}],"execution_count":72},{"source":"# Project Conclusion and Insights\n\nIn this project, we conducted a detailed analysis of stock closing prices using Python and pandas. We started by creating a DataFrame with sample data, which included dates and closing prices. The primary objective was to analyze the stock's performance over a given period and extract meaningful insights.\n\n## Key Steps and Findings\n\n1. **Data Preparation**:\n   - We initialized a DataFrame with sample data, ensuring that the 'Date' column was properly formatted as a datetime object and set as the index for easier time-series analysis.\n   - This step is crucial for ensuring that the data is in a suitable format for subsequent analysis, allowing for efficient manipulation and querying of time-series data.\n\n2. **Identifying Key Dates**:\n   - **Highest Closing Price**: We identified the date with the highest closing price, which provides insight into peak market performance. This can be particularly useful for understanding market highs and potential resistance levels.\n   - **Lowest Closing Price**: Similarly, we found the date with the lowest closing price, indicating the weakest market performance during the period. This helps in identifying market lows and potential support levels.\n\n3. **Change Analysis**:\n   - By calculating the change in closing prices from the previous day, we were able to determine the date with the largest change, highlighting significant market volatility. This analysis is essential for understanding daily market fluctuations and can be used to gauge market sentiment and investor reactions.\n\n## Final Insights\n\n- **Performance Overview**: The analysis provided a clear view of the stock's performance over the specified period, allowing us to pinpoint days of significant market activity. This overview is valuable for both short-term traders and long-term investors.\n- **Market Entry and Exit Points**: Understanding the dates of highest and lowest closing prices can help investors make informed decisions about market entry and exit points. By identifying these key dates, investors can better time their trades to maximize returns or minimize losses.\n- **Volatility and Risk Assessment**: The change analysis is crucial for risk assessment, as it identifies periods of high volatility that may require strategic adjustments. Investors can use this information to adjust their portfolios, hedge against potential risks, or capitalize on volatile market conditions.\n\nOverall, this project demonstrated the power of data analysis in financial markets, showcasing how historical data can be leveraged to gain insights and guide investment strategies. The workflow established here can be applied to larger datasets for more comprehensive analyses, enabling more robust and data-driven decision-making processes in the financial sector.","metadata":{},"cell_type":"markdown","id":"14f80b94-b291-470d-8031-247b04ffd360"}],"metadata":{"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}