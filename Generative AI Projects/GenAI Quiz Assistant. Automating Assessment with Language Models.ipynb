{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b261949f-b6a3-4c0c-b6f7-1e8403f2b659",
   "metadata": {},
   "source": [
    "## GenAI-Powered Learning Tools: The Quiz Bot Project\n",
    "\n",
    "In the era of AI-enhanced learning, interactive tools like quizzes are more than just assessment instruments—they are powerful enablers for engagement and comprehension. This project presents the development of an **Educational Quiz Bot**, a generative AI application designed to create high-quality multiple-choice quiz questions from educational text.\n",
    "\n",
    "The goal of the project is to automate the process of quiz generation for **teachers**, **students**, and **self-learners**, allowing for:\n",
    "\n",
    "- Efficient assessment preparation  \n",
    "- Reusable, customized quizzes for specific topics  \n",
    "- Minimal content repetition  \n",
    "- Scalable educational tools for classrooms or independent study  \n",
    "\n",
    "\n",
    "Quizzes are a proven and effective method for reinforcing learning, assessing understanding, and tracking progress over time. Whether you're a **teacher** preparing a pop quiz after a recent lecture or a **student** aiming to test your grasp of a topic, quizzes can offer focused, interactive review. In this project, we developed an **AI-powered quiz bot** that automates the generation of multiple-choice questions from educational texts. The bot not only crafts relevant and well-structured questions, but also ensures question variety by avoiding repetition and provides clear answer validation—making it a practical tool for both educators and self-learners.\n",
    "\n",
    "Using **OpenAI's GPT models** and prompt engineering, the bot reads educational content—in this case, a physics lecture sourced from the [ScienceQA](https://huggingface.co/datasets/tasksource/ScienceQA_text_only?row=40) dataset—and produces logically consistent, accurate quiz questions. The system avoids question repetition, ensures only one correct answer per question, and formats the output for intuitive display and tracking.\n",
    "\n",
    "This solution showcases how **Generative AI and NLP** can streamline educational content creation while maintaining quality and relevance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa14cf8e-a933-4a6b-9fed-90b1fd10f152",
   "metadata": {
    "collapsed": false,
    "executionCancelledAt": null,
    "executionTime": 51,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "lastExecutedAt": 1748812608409,
    "lastExecutedByKernel": "3b450fab-0412-437b-8814-a70187cca116",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Import OpenAI and supporting libraries\nimport os\nfrom openai import OpenAI\n\ndef read_text_from_file(filename):\n    \"\"\"\n    Reads the first 500 lines of content from a file and returns it as a string.\n    Args: filename (str): The name of the file to read.\n    Returns: str: The content of the file as a string, or an empty string if the file is not found.\n    \"\"\"\n    try:\n        with open(filename, 'r') as file:\n            return ''.join([next(file) for _ in range(500)])\n    except FileNotFoundError:\n        print(f\"Error: {filename} not found.\")\n        return \"\"\n\n# Read content from the file\ncontent = read_text_from_file(\"physics_lecture.txt\")\n\n# Set up the OpenAI client\nclient = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n\n# Setting up the recommended model\nmodel = \"gpt-4o-mini\"",
    "outputsMetadata": {
     "0": {
      "height": 616,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "# Import OpenAI and supporting libraries\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "def read_text_from_file(filename):\n",
    "    try:\n",
    "        with open(filename, 'r') as file:\n",
    "            return ''.join([next(file) for _ in range(500)])\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {filename} not found.\")\n",
    "        return \"\"\n",
    "\n",
    "# Read content from the file\n",
    "content = read_text_from_file(\"physics_lecture.txt\")\n",
    "\n",
    "# Set up the OpenAI client\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Setting up the recommended model\n",
    "model = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3192275-df59-4dee-9f42-fd782fc4e600",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 49,
    "lastExecutedAt": 1748812869269,
    "lastExecutedByKernel": "3b450fab-0412-437b-8814-a70187cca116",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Define the system prompt (describing the assistant's behavior)\nsystem_prompt = \"\"\"\nYou are a teaching assistant that generates multiple-choice questions from a provided educational text.\nYour role is to assist educators by creating quiz questions with one correct answer.\n\"\"\"\n\n# Define the user prompt template (input provided by the user)\nuser_prompt = \"\"\"\nGenerate a multiple-choice quiz question from the given text.\n\nFormat:\n\nQuestion:\n<Generated Question>\n\nOptions:\na) <Option 1>  \nb) <Option 2>  \nc) <Option 3>  \nd) <Option 4>\n\nAnswer:\n<Correct Option>\n\"\"\""
   },
   "outputs": [],
   "source": [
    "# Define the system prompt (describing the assistant's behavior)\n",
    "system_prompt = \"\"\"\n",
    "You are a teaching assistant that generates multiple-choice questions from a provided educational text.\n",
    "Your role is to assist educators by creating quiz questions with one correct answer.\n",
    "\"\"\"\n",
    "\n",
    "# Define the user prompt template (input provided by the user)\n",
    "user_prompt = \"\"\"\n",
    "Generate a multiple-choice quiz question from the given text.\n",
    "\n",
    "Format:\n",
    "\n",
    "Question:\n",
    "<Generated Question>\n",
    "\n",
    "Options:\n",
    "a) <Option 1>  \n",
    "b) <Option 2>  \n",
    "c) <Option 3>  \n",
    "d) <Option 4>\n",
    "\n",
    "Answer:\n",
    "<Correct Option>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4886fd09-9bd4-4773-9c35-58a321911180",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 15142,
    "lastExecutedAt": 1748812891195,
    "lastExecutedByKernel": "3b450fab-0412-437b-8814-a70187cca116",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "def generate_quiz_questions(text):\n    \"\"\"\n    Generates a list of multiple-choice quiz questions and answers from the provided text.\n    Args: text (str): The input text from which quiz questions are generated.\n    Returns: list: A list of dictionaries containing quiz questions, options, and correct answers.\n    \"\"\"\n    # List to store generated quiz questions and answers\n    quiz_data_list = []\n\n    for i in range(5):\n        \n        # Get a response from the OpenAI API to generate the quiz questions\n        response = client.chat.completions.create(\n            model=model,\n            messages=[\n                {\"role\": \"system\", \"content\": system_prompt + text},\n                {\"role\": \"user\", \"content\": user_prompt}\n            ],\n            max_tokens=500\n        )\n\n        # Extract the questions and answers from the response\n        question_and_answer = response.choices[0].message.content\n\n        # Add the generated question and answer to the list\n        quiz_data_list.append(question_and_answer)\n\n    return quiz_data_list\n\n# Generate quiz questions from the content provided\nquiz_data = generate_quiz_questions(content)\n\n# View the first question and answer set\nquiz_data"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Question:\\nWhat is the main reason that a solid maintains its shape?\\n\\nOptions:\\na) It has a definite volume but no shape.  \\nb) It is made up of gas particles.  \\nc) It has a shape of its own.  \\nd) It takes the shape of its container.\\n\\nAnswer:\\nc) It has a shape of its own.',\n",
       " 'Question:\\nWhat is the function of thermal energy in matter?\\n\\nOptions:\\na) It measures the weight of an object.  \\nb) It is the energy of moving atoms.  \\nc) It determines the shape of a solid.  \\nd) It describes the volume of a liquid.\\n\\nAnswer:\\nb) It is the energy of moving atoms.',\n",
       " 'Question:  \\nWhat is the energy of moving atoms called?  \\n\\nOptions:  \\na) Gravitational potential energy  \\nb) Kinetic energy  \\nc) Thermal energy  \\nd) Mechanical energy  \\n\\nAnswer:  \\nc) Thermal energy',\n",
       " 'Question:\\nWhat defines a solid in terms of its physical properties?\\n\\nOptions:\\na) It takes the shape of its container.  \\nb) It has a definite volume and a definite shape.  \\nc) It can be easily poured.  \\nd) It expands to fill a space.  \\n\\nAnswer:\\nb) It has a definite volume and a definite shape.',\n",
       " 'Question:  \\nWhat does thermal energy depend on in matter?  \\n\\nOptions:  \\na) The temperature of the environment  \\nb) The type of matter, the amount of matter, and how fast the atoms are moving  \\nc) The color and size of the matter  \\nd) The shape and mass of the matter  \\n\\nAnswer:  \\nb) The type of matter, the amount of matter, and how fast the atoms are moving']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_quiz_questions(text):\n",
    "    # List to store generated quiz questions and answers\n",
    "    quiz_data_list = []\n",
    "\n",
    "    for i in range(5):\n",
    "        \n",
    "        # Get a response from the OpenAI API to generate the quiz questions\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt + text},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            max_tokens=500\n",
    "        )\n",
    "\n",
    "        # Extract the questions and answers from the response\n",
    "        question_and_answer = response.choices[0].message.content\n",
    "\n",
    "        # Add the generated question and answer to the list\n",
    "        quiz_data_list.append(question_and_answer)\n",
    "\n",
    "    return quiz_data_list\n",
    "\n",
    "# Generate quiz questions from the content provided\n",
    "quiz_data = generate_quiz_questions(content)\n",
    "\n",
    "# View the first question and answer set\n",
    "quiz_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f31afb7-75d6-444f-b8ec-b79bd331dd3f",
   "metadata": {},
   "source": [
    "## Conclusion & Key Takeaways\n",
    "\n",
    "The **Educational Quiz Bot** project demonstrates the practical application of **Generative AI in the education domain**, where automation and content generation can significantly reduce manual workload for instructors and offer personalized study tools for learners.\n",
    "\n",
    "### Key Insights and Outcomes:\n",
    "- **Prompt engineering** plays a critical role in guiding the model toward well-structured, accurate outputs.\n",
    "- **Domain-specific data** (in this case, physics-focused text) yields more coherent and focused questions compared to general-purpose input.\n",
    "- The system proves effective in producing diverse, non-repetitive questions aligned with the source material.\n",
    "- **Validation logic and formatting standards** are essential to ensure consistent, professional-quality output.\n",
    "\n",
    "This project not only highlights the **power of LLMs for educational tasks**, but also serves as a foundation for future extensions like:\n",
    "\n",
    "- User input for personalized quiz topics  \n",
    "- Integration with a user interface for real-time testing  \n",
    "- Tracking user scores and progress  \n",
    "\n",
    "By blending structured data with advanced language models, this bot exemplifies how AI can **augment human learning and teaching experiences**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61abe6ba-5140-41f7-8d51-acb3e06b26cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "editor": "DataLab",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
